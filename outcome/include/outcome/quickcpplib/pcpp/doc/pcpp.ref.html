<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>pcpp API documentation</title>
    <meta name="description" content="" />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>


  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">


    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#pcpp.OutputDirective">OutputDirective</a></span>
        
        </li>
        <li class="mono">
        <span class="class_name"><a href="#pcpp.Preprocessor">Preprocessor</a></span>
        
          
  <ul>
    <li class="mono"><a href="#pcpp.Preprocessor.__init__">__init__</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.add_path">add_path</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.collect_args">collect_args</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.define">define</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.evalexpr">evalexpr</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.expand_macros">expand_macros</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.group_lines">group_lines</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.include">include</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.macro_expand_args">macro_expand_args</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.macro_prescan">macro_prescan</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_comment">on_comment</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_directive_handle">on_directive_handle</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_directive_unknown">on_directive_unknown</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_error">on_error</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_include_not_found">on_include_not_found</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_potential_include_guard">on_potential_include_guard</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_unknown_macro_in_defined_expr">on_unknown_macro_in_defined_expr</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.on_unknown_macro_in_expr">on_unknown_macro_in_expr</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.parse">parse</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.parsegen">parsegen</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.token">token</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.tokenize">tokenize</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.tokenstrip">tokenstrip</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.undef">undef</a></li>
    <li class="mono"><a href="#pcpp.Preprocessor.write">write</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">pcpp</span> module</h1>
  
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp', this);">Show source &equiv;</a></p>
  <div id="source-pcpp" class="source">
    <pre><code>#!/usr/bin/python
# Python C99 conforming preprocessor useful for generating single include files
# (C) 2017 Niall Douglas http://www.nedproductions.biz/
# and (C) 2007-2017 David Beazley http://www.dabeaz.com/
# Started: Feb 2017
#
# This C preprocessor was originally written by David Beazley and the
# original can be found at https://github.com/dabeaz/ply/blob/master/ply/cpp.py
# This edition substantially improves on standards conforming output,
# getting quite close to what clang or GCC outputs.

from __future__ import generators, print_function

__all__ = ['Preprocessor', 'OutputDirective']

import sys, traceback

# Some Python 3 compatibility shims
if sys.version_info.major < 3:
    STRING_TYPES = (str, unicode)
    FILE_TYPES = file
else:
    STRING_TYPES = str
    xrange = range
    import io
    FILE_TYPES = io.IOBase

# -----------------------------------------------------------------------------
# Default preprocessor lexer definitions.   These tokens are enough to get
# a basic preprocessor working.   Other modules may import these if they want
# -----------------------------------------------------------------------------

tokens = (
   'CPP_ID','CPP_INTEGER', 'CPP_FLOAT', 'CPP_STRING', 'CPP_CHAR', 'CPP_WS', 'CPP_COMMENT1', 'CPP_COMMENT2', 'CPP_POUND','CPP_DPOUND'
)

literals = "+-*/%|&~^<>=!?()[]{}.,;:\\\'\""

# Whitespace, but don't match past the end of a line
def t_CPP_WS(t):
    r'([ \t]+|\n)'
    t.lexer.lineno += t.value.count("\n")
    return t

t_CPP_POUND = r'\#'
t_CPP_DPOUND = r'\#\#'

# Identifier
t_CPP_ID = r'[A-Za-z_][\w_]*'

# Integer literal
def CPP_INTEGER(t):
    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'
    return t

t_CPP_INTEGER = CPP_INTEGER

# Floating literal
t_CPP_FLOAT = r'((\d+)(\.\d+)(e(\+|-)?(\d+))? | (\d+)e(\+|-)?(\d+))([lL]|[fF])?'

# String literal
def t_CPP_STRING(t):
    r'\"([^\\\n]|(\\(.|\n)))*?\"'
    t.lexer.lineno += t.value.count("\n")
    return t

# Character constant 'c' or L'c'
def t_CPP_CHAR(t):
    r'(L)?\'([^\\\n]|(\\(.|\n)))*?\''
    t.lexer.lineno += t.value.count("\n")
    return t

# Comment
def t_CPP_COMMENT1(t):
    r'(/\*(.|\n)*?\*/)'
    ncr = t.value.count("\n")
    t.lexer.lineno += ncr
    return t

# Line comment
def t_CPP_COMMENT2(t):
    r'(//[^\n]*)'
    return t
    
def t_error(t):
    t.type = t.value[0]
    t.value = t.value[0]
    t.lexer.skip(1)
    return t

import re
import copy
import time
import os.path
from ply.lex import LexToken

# -----------------------------------------------------------------------------
# trigraph()
# 
# Given an input string, this function replaces all trigraph sequences. 
# The following mapping is used:
#
#     ??=    #
#     ??/    \
#     ??'    ^
#     ??(    [
#     ??)    ]
#     ??!    |
#     ??<    {
#     ??>    }
#     ??-    ~
# -----------------------------------------------------------------------------

_trigraph_pat = re.compile(r'''\?\?[=/\'\(\)\!<>\-]''')
_trigraph_rep = {
    '=':'#',
    '/':'\\',
    "'":'^',
    '(':'[',
    ')':']',
    '!':'|',
    '<':'{',
    '>':'}',
    '-':'~'
}

def trigraph(input):
    return _trigraph_pat.sub(lambda g: _trigraph_rep[g.group()[-1]],input)

# ------------------------------------------------------------------
# Macro object
#
# This object holds information about preprocessor macros
#
#    .name      - Macro name (string)
#    .value     - Macro value (a list of tokens)
#    .arglist   - List of argument names
#    .variadic  - Boolean indicating whether or not variadic macro
#    .vararg    - Name of the variadic parameter
#
# When a macro is created, the macro replacement token sequence is
# pre-scanned and used to create patch lists that are later used
# during macro expansion
# ------------------------------------------------------------------

class Macro(object):
    def __init__(self,name,value,arglist=None,variadic=False):
        self.name = name
        self.value = value
        self.arglist = arglist
        self.variadic = variadic
        if variadic:
            self.vararg = arglist[-1]
        self.source = None
    def __repr__(self):
        return "%s(%s)=%s" % (self.name, self.arglist, self.value)

# ------------------------------------------------------------------
# Preprocessor event hooks
#
# Override these to customise preprocessing
# ------------------------------------------------------------------

class OutputDirective(Exception):
    """Raise this exception to abort processing of a preprocessor directive and
    to instead output it as is into the output"""
    pass

class PreprocessorHooks(object):
    """Override these in your subclass of Preprocessor to customise preprocessing"""
    def __init__(self):
        self.lastdirective = None

    def on_error(self,file,line,msg):
        """Called when the preprocessor has encountered an error, e.g. malformed input.
        
        The default simply prints to stderr and increments the return code.
        """
        print("%s:%d error: %s" % (file,line,msg), file = sys.stderr)
        self.return_code += 1
        
    def on_include_not_found(self,is_system_include,curdir,includepath):
        """Called when a #include wasn't found.
        
        Return None to ignore, raise OutputDirective to pass through, else return
        a suitable path. Remember that Preprocessor.add_path() lets you add search paths.
        
        The default calls self.on_error() with a suitable error message about the
        include file not found and raises OutputDirective (pass through).
        """
        self.on_error(self.lastdirective.source,self.lastdirective.lineno, "Include file '%s' not found" % includepath)
        raise OutputDirective()
        
    def on_unknown_macro_in_defined_expr(self,tok):
        """Called when an expression passed to an #if contained a defined operator
        performed on something unknown.
        
        Return True if to treat it as defined, False if to treat it as undefined,
        raise OutputDirective to pass through without execution, or return None to
        pass through the mostly expanded #if expression apart from the unknown defined.
        
        The default returns False, as per the C standard.
        """
        return False

    def on_unknown_macro_in_expr(self,tok):
        """Called when an expression passed to an #if contained something unknown.
        
        Return what value it should be, raise OutputDirective to pass through
        without execution, or return None to pass through the mostly expanded #if
        expression apart from the unknown item.
        
        The default returns a token for an integer 0L, as per the C standard.
        """
        tok.type = self.t_INTEGER
        tok.value = self.t_INTEGER_TYPE("0L")
        return tok
    
    def on_directive_handle(self,directive,toks,ifpassthru):
        """Called when there is one of
        
        define, include, undef, ifdef, ifndef, if, elif, else, endif
        
        Return True to execute and remove from the output, return False to
        remove from the output, raise OutputDirective to pass through without
        execution, or return None to execute AND pass through to the output
        (this only works for #define, #undef).
        
        The default returns True (execute and remove from the output).
        """
        self.lastdirective = directive
        return True
        
    def on_directive_unknown(self,directive,toks,ifpassthru):
        """Called when the preprocessor encounters a #directive it doesn't understand.
        This is actually quite an extensive list as it currently only understands:
        
        define, include, undef, ifdef, ifndef, if, elif, else, endif
        
        Return True or False to remove from the output, or else raise OutputDirective
        or return None to pass through into the output.
        
        The default handles #error and #warning by printing to stderr and returning True
        (remove from output). For everything else it returns None (pass through into output).
        """
        if directive.value == 'error':
            print("%s:%d error: %s" % (directive.source,directive.lineno,''.join(tok.value for tok in toks)), file = sys.stderr)
            self.return_code += 1
            return True
        elif directive.value == 'warning':
            print("%s:%d warning: %s" % (directive.source,directive.lineno,''.join(tok.value for tok in toks)), file = sys.stderr)
            return True
        return None
        
    def on_potential_include_guard(self,macro):
        """Called when the preprocessor encounters an #ifndef macro or an #if !defined(macro)
        as the first non-whitespace thing in a file. Unlike the other hooks, macro is a string,
        not a token.
        """
        pass
    
    def on_comment(self,tok):
        """Called when the preprocessor encounters a comment token. You can modify the token
        in place, or do nothing to let the comment pass through.
        
        The default modifies the token to become whitespace, becoming a single space if the
        comment is a block comment, else a single new line if the comment is a line comment.
        """
        if tok.type == self.t_COMMENT1:
            tok.value = ' '
        elif tok.type == self.t_COMMENT2:
            tok.value = '\n'
        tok.type = 'CPP_WS'

# ------------------------------------------------------------------
# Preprocessor object
#
# Object representing a preprocessor.  Contains macro definitions,
# include directories, and other information
# ------------------------------------------------------------------

class Preprocessor(PreprocessorHooks):    
    def __init__(self,lexer=None):
        super(Preprocessor, self).__init__()
        if lexer is None:
            import ply.lex as lex
            lexer = lex.lex()
        self.lexer = lexer
        self.macros = { }
        self.path = []
        self.temp_path = []
        self.include_once = {}
        self.return_code = 0
        self.debugout = None
        self.auto_pragma_once_enabled = True
        self.line_directive = '#line'

        # Probe the lexer for selected tokens
        self.__lexprobe()

        tm = time.localtime()
        self.define("__DATE__ \"%s\"" % time.strftime("%b %d %Y",tm))
        self.define("__TIME__ \"%s\"" % time.strftime("%H:%M:%S",tm))
        self.define("__PCPP__ 1")
        self.countermacro = 0
        self.parser = None

    # -----------------------------------------------------------------------------
    # tokenize()
    #
    # Utility function. Given a string of text, tokenize into a list of tokens
    # -----------------------------------------------------------------------------

    def tokenize(self,text):
        """Utility function. Given a string of text, tokenize into a list of tokens"""
        tokens = []
        self.lexer.input(text)
        while True:
            tok = self.lexer.token()
            if not tok: break
            tokens.append(tok)
        return tokens

    # ----------------------------------------------------------------------
    # __lexprobe()
    #
    # This method probes the preprocessor lexer object to discover
    # the token types of symbols that are important to the preprocessor.
    # If this works right, the preprocessor will simply "work"
    # with any suitable lexer regardless of how tokens have been named.
    # ----------------------------------------------------------------------

    def __lexprobe(self):

        # Determine the token type for identifiers
        self.lexer.input("identifier")
        tok = self.lexer.token()
        if not tok or tok.value != "identifier":
            print("Couldn't determine identifier type")
        else:
            self.t_ID = tok.type

        # Determine the token type for integers
        self.lexer.input("12345")
        tok = self.lexer.token()
        if not tok or int(tok.value) != 12345:
            print("Couldn't determine integer type")
        else:
            self.t_INTEGER = tok.type
            self.t_INTEGER_TYPE = type(tok.value)

        # Determine the token type for strings enclosed in double quotes
        self.lexer.input("\"filename\"")
        tok = self.lexer.token()
        if not tok or tok.value != "\"filename\"":
            print("Couldn't determine string type")
        else:
            self.t_STRING = tok.type

        # Determine the token type for whitespace--if any
        self.lexer.input("  ")
        tok = self.lexer.token()
        if not tok or tok.value != "  ":
            self.t_SPACE = None
        else:
            self.t_SPACE = tok.type

        # Determine the token type for newlines
        self.lexer.input("\n")
        tok = self.lexer.token()
        if not tok or tok.value != "\n":
            self.t_NEWLINE = None
            print("Couldn't determine token for newlines")
        else:
            self.t_NEWLINE = tok.type

        self.t_WS = (self.t_SPACE, self.t_NEWLINE)

        self.lexer.input("##")
        tok = self.lexer.token()
        if not tok or tok.value != "##":
            print("Couldn't determine token for token pasting operator")
        else:
            self.t_DPOUND = tok.type

        self.lexer.input("?")
        tok = self.lexer.token()
        if not tok or tok.value != "?":
            print("Couldn't determine token for ternary operator")
        else:
            self.t_TERNARY = tok.type

        self.lexer.input(":")
        tok = self.lexer.token()
        if not tok or tok.value != ":":
            print("Couldn't determine token for ternary operator")
        else:
            self.t_COLON = tok.type

        self.lexer.input("/* comment */")
        tok = self.lexer.token()
        if not tok or tok.value != "/* comment */":
            print("Couldn't determine comment type")
        else:
            self.t_COMMENT1 = tok.type

        self.lexer.input("// comment")
        tok = self.lexer.token()
        if not tok or tok.value != "// comment":
            print("Couldn't determine comment type")
        else:
            self.t_COMMENT2 = tok.type
            
        self.t_COMMENT = (self.t_COMMENT1, self.t_COMMENT2)

        # Check for other characters used by the preprocessor
        chars = [ '<','>','#','##','\\','(',')',',','.']
        for c in chars:
            self.lexer.input(c)
            tok = self.lexer.token()
            if not tok or tok.value != c:
                print("Unable to lex '%s' required for preprocessor" % c)

    # ----------------------------------------------------------------------
    # add_path()
    #
    # Adds a search path to the preprocessor.  
    # ----------------------------------------------------------------------

    def add_path(self,path):
        """Adds a search path to the preprocessor. """
        self.path.append(path)

    # ----------------------------------------------------------------------
    # group_lines()
    #
    # Given an input string, this function splits it into lines.  Trailing whitespace
    # is removed.   Any line ending with \ is grouped with the next line.  This
    # function forms the lowest level of the preprocessor---grouping into text into
    # a line-by-line format.
    # ----------------------------------------------------------------------

    def group_lines(self,input,source):
        """Given an input string, this function splits it into lines.  Trailing whitespace
        is removed.   Any line ending with \ is grouped with the next line.  This
        function forms the lowest level of the preprocessor---grouping into text into
        a line-by-line format.
        """
        lex = self.lexer.clone()
        lines = [x.rstrip() for x in input.splitlines()]
        for i in xrange(len(lines)):
            j = i+1
            while lines[i].endswith('\\') and (j < len(lines)):
                lines[i] = lines[i][:-1]+lines[j]
                lines[j] = ""
                j += 1

        input = "\n".join(lines)
        lex.input(input)
        lex.lineno = 1

        current_line = []
        while True:
            tok = lex.token()
            if not tok:
                break
            tok.source = source
            current_line.append(tok)
            if tok.type in self.t_WS and '\n' in tok.value:
                yield current_line
                current_line = []

        if current_line:
            nltok = copy.copy(current_line[-1])
            nltok.type = self.t_NEWLINE
            nltok.value = '\n'
            current_line.append(nltok)
            yield current_line

    # ----------------------------------------------------------------------
    # tokenstrip()
    # 
    # Remove leading/trailing whitespace tokens from a token list
    # ----------------------------------------------------------------------

    def tokenstrip(self,tokens):
        """Remove leading/trailing whitespace tokens from a token list"""
        i = 0
        while i < len(tokens) and tokens[i].type in self.t_WS:
            i += 1
        del tokens[:i]
        i = len(tokens)-1
        while i >= 0 and tokens[i].type in self.t_WS:
            i -= 1
        del tokens[i+1:]
        return tokens


    # ----------------------------------------------------------------------
    # collect_args()
    #
    # Collects comma separated arguments from a list of tokens.   The arguments
    # must be enclosed in parenthesis.  Returns a tuple (tokencount,args,positions)
    # where tokencount is the number of tokens consumed, args is a list of arguments,
    # and positions is a list of integers containing the starting index of each
    # argument.  Each argument is represented by a list of tokens.
    #
    # When collecting arguments, leading and trailing whitespace is removed
    # from each argument.  
    #
    # This function properly handles nested parenthesis and commas---these do not
    # define new arguments.
    # ----------------------------------------------------------------------

    def collect_args(self,tokenlist,ignore_errors=False):
        """Collects comma separated arguments from a list of tokens.   The arguments
        must be enclosed in parenthesis.  Returns a tuple (tokencount,args,positions)
        where tokencount is the number of tokens consumed, args is a list of arguments,
        and positions is a list of integers containing the starting index of each
        argument.  Each argument is represented by a list of tokens.
        
        When collecting arguments, leading and trailing whitespace is removed
        from each argument.  
        
        This function properly handles nested parenthesis and commas---these do not
        define new arguments."""
        args = []
        positions = []
        current_arg = []
        nesting = 1
        tokenlen = len(tokenlist)
    
        # Search for the opening '('.
        i = 0
        while (i < tokenlen) and (tokenlist[i].type in self.t_WS):
            i += 1

        if (i < tokenlen) and (tokenlist[i].value == '('):
            positions.append(i+1)
        else:
            if not ignore_errors:
                self.on_error(tokenlist[0].source,tokenlist[0].lineno,"Missing '(' in macro arguments")
            return 0, [], []

        i += 1

        while i < tokenlen:
            t = tokenlist[i]
            if t.value == '(':
                current_arg.append(t)
                nesting += 1
            elif t.value == ')':
                nesting -= 1
                if nesting == 0:
                    args.append(self.tokenstrip(current_arg))
                    positions.append(i)
                    return i+1,args,positions
                current_arg.append(t)
            elif t.value == ',' and nesting == 1:
                args.append(self.tokenstrip(current_arg))
                positions.append(i+1)
                current_arg = []
            else:
                current_arg.append(t)
            i += 1
    
        # Missing end argument
        if not ignore_errors:
            self.on_error(tokenlist[-1].source,tokenlist[-1].lineno,"Missing ')' in macro arguments")
        return 0, [],[]

    # ----------------------------------------------------------------------
    # macro_prescan()
    #
    # Examine the macro value (token sequence) and identify patch points
    # This is used to speed up macro expansion later on---we'll know
    # right away where to apply patches to the value to form the expansion
    # ----------------------------------------------------------------------
    
    def macro_prescan(self,macro):
        """Examine the macro value (token sequence) and identify patch points
        This is used to speed up macro expansion later on---we'll know
        right away where to apply patches to the value to form the expansion"""
        macro.patch     = []             # Standard macro arguments 
        macro.str_patch = []             # String conversion expansion
        macro.var_comma_patch = []       # Variadic macro comma patch
        i = 0
        #print "BEFORE", macro.value
        while i < len(macro.value):
            if macro.value[i].type == self.t_ID and macro.value[i].value in macro.arglist:
                argnum = macro.arglist.index(macro.value[i].value)
                # Conversion of argument to a string
                j = i - 1
                while j >= 0 and macro.value[j].type in self.t_WS:
                    j -= 1
                if j >= 0 and macro.value[j].value == '#':
                    macro.value[i] = copy.copy(macro.value[i])
                    macro.value[i].type = self.t_STRING
                    while i > j:
                        del macro.value[j]
                        i -= 1
                    macro.str_patch.append((argnum,i))
                    continue
                # Concatenation
                elif (i > 0 and macro.value[i-1].value == '##'):
                    macro.patch.append(('t',argnum,i))
                    i += 1
                    continue
                elif ((i+1) < len(macro.value) and macro.value[i+1].value == '##'):
                    macro.patch.append(('t',argnum,i))
                    i += 1
                    continue
                # Standard expansion
                else:
                    macro.patch.append(('e',argnum,i))
            elif macro.value[i].value == '##':
                if macro.variadic and (i > 0) and (macro.value[i-1].value == ',') and \
                        ((i+1) < len(macro.value)) and (macro.value[i+1].type == self.t_ID) and \
                        (macro.value[i+1].value == macro.vararg):
                    macro.var_comma_patch.append(i-1)
            i += 1
        macro.patch.sort(key=lambda x: x[2],reverse=True)
        #print "AFTER", macro.value

    # ----------------------------------------------------------------------
    # macro_expand_args()
    #
    # Given a Macro and list of arguments (each a token list), this method
    # returns an expanded version of a macro.  The return value is a token sequence
    # representing the replacement macro tokens
    # ----------------------------------------------------------------------

    def macro_expand_args(self,macro,args):
        """Given a Macro and list of arguments (each a token list), this method
        returns an expanded version of a macro.  The return value is a token sequence
        representing the replacement macro tokens"""
        # Make a copy of the macro token sequence
        rep = [copy.copy(_x) for _x in macro.value]

        # Make string expansion patches.  These do not alter the length of the replacement sequence
        str_expansion = {}
        for argnum, i in macro.str_patch:
            if argnum not in str_expansion:
                # Strip all non-space whitespace before stringization
                tokens = copy.copy(args[argnum])
                for j in xrange(len(tokens)):
                    if tokens[j].type in self.t_WS:
                        tokens[j].value = ' '
                # Collapse all multiple whitespace too
                j = 0
                while j < len(tokens) - 1:
                    if tokens[j].type in self.t_WS and tokens[j+1].type in self.t_WS:
                        del tokens[j+1]
                    else:
                        j += 1
                str = "".join([x.value for x in tokens])
                str = str.replace("\\","\\\\").replace('"', '\\"')
                str_expansion[argnum] = '"' + str + '"'
            rep[i] = copy.copy(rep[i])
            rep[i].value = str_expansion[argnum]

        # Make the variadic macro comma patch.  If the variadic macro argument is empty, we get rid
        comma_patch = False
        if macro.variadic and not args[-1]:
            for i in macro.var_comma_patch:
                rep[i] = None
                comma_patch = True

        # Make all other patches.   The order of these matters.  It is assumed that the patch list
        # has been sorted in reverse order of patch location since replacements will cause the
        # size of the replacement sequence to expand from the patch point.
        
        expanded = { }
        #print "***", macro
        #print macro.patch
        for ptype, argnum, i in macro.patch:
            # Concatenation.   Argument is left unexpanded
            if ptype == 't':
                rep[i:i+1] = args[argnum]
            # Normal expansion.  Argument is macro expanded first
            elif ptype == 'e':
                if argnum not in expanded:
                    expanded[argnum] = self.expand_macros(args[argnum])
                rep[i:i+1] = expanded[argnum]

        # Get rid of removed comma if necessary
        if comma_patch:
            rep = [_i for _i in rep if _i]
            
        # Do a token concatenation pass, stitching any tokens separated by ## into a single token
        while len(rep) and rep[0].type == self.t_DPOUND:
            del rep[0]
        while len(rep) and rep[-1].type == self.t_DPOUND:
            del rep[-1]
        i = 1
        while i < len(rep) - 1:
            if rep[i].type == self.t_DPOUND:
                j = i + 1
                while rep[j].type == self.t_DPOUND:
                    j += 1
                rep[i-1].type = self.t_ID
                rep[i-1].value += rep[j].value
                while j >= i:
                    del rep[i]
                    j -= 1
            else:
                i += 1

        #print rep
        return rep


    # ----------------------------------------------------------------------
    # expand_macros()
    #
    # Given a list of tokens, this function performs macro expansion.
    # ----------------------------------------------------------------------

    def expand_macros(self,tokens,expanding_from=[]):
        """Given a list of tokens, this function performs macro expansion."""
        # Each token needs to track from which macros it has been expanded from to prevent recursion
        for tok in tokens:
            if not hasattr(tok, 'expanded_from'):
                tok.expanded_from = []
        i = 0
        #print "*** EXPAND MACROS in", "".join([t.value for t in tokens]), "expanding_from=", expanding_from
        #print tokens
        #print [(t.value, t.expanded_from) for t in tokens]
        while i < len(tokens):
            t = tokens[i]
            if t.type == self.t_ID:
                if t.value in self.macros and t.value not in t.expanded_from and t.value not in expanding_from:
                    # Yes, we found a macro match
                    m = self.macros[t.value]
                    if m.arglist is None:
                        # A simple macro
                        rep = [copy.copy(_x) for _x in m.value]
                        ex = self.expand_macros(rep, expanding_from + [t.value])
                        #print "\nExpanding macro", m, "\ninto", ex, "\nreplacing", tokens[i:i+1]
                        for e in ex:
                            e.source = t.source
                            e.lineno = t.lineno
                            if not hasattr(e, 'expanded_from'):
                                e.expanded_from = []
                            e.expanded_from.append(t.value)
                        tokens[i:i+1] = ex
                    else:
                        # A macro with arguments
                        j = i + 1
                        while j < len(tokens) and (tokens[j].type in self.t_WS or tokens[j].type in self.t_COMMENT):
                            j += 1
                        # A function like macro without an invocation list is to be ignored
                        if j == len(tokens) or tokens[j].value != '(':
                            i = j
                        else:
                            tokcount,args,positions = self.collect_args(tokens[j:], True)
                            if tokcount == 0:
                                # Unclosed parameter list, just bail out
                                break
                            if (not m.variadic
                                # A no arg or single arg consuming macro is permitted to be expanded with nothing
                                and (args != [[]] or len(m.arglist) > 1)
                                and len(args) !=  len(m.arglist)):
                                self.on_error(t.source,t.lineno,"Macro %s requires %d arguments but was passed %d" % (t.value,len(m.arglist),len(args)))
                                i = j + tokcount
                            elif m.variadic and len(args) < len(m.arglist)-1:
                                if len(m.arglist) > 2:
                                    self.on_error(t.source,t.lineno,"Macro %s must have at least %d arguments" % (t.value, len(m.arglist)-1))
                                else:
                                    self.on_error(t.source,t.lineno,"Macro %s must have at least %d argument" % (t.value, len(m.arglist)-1))
                                i = j + tokcount
                            else:
                                if m.variadic:
                                    if len(args) == len(m.arglist)-1:
                                        args.append([])
                                    else:
                                        args[len(m.arglist)-1] = tokens[j+positions[len(m.arglist)-1]:j+tokcount-1]
                                        del args[len(m.arglist):]
                                else:
                                    # If we called a single arg macro with empty, fake extend args
                                    while len(args) < len(m.arglist):
                                        args.append([])
                                        
                                # Get macro replacement text
                                rep = self.macro_expand_args(m,args)
                                ex = self.expand_macros(rep, expanding_from + [t.value])
                                for e in ex:
                                    e.source = t.source
                                    e.lineno = t.lineno
                                    if not hasattr(e, 'expanded_from'):
                                        e.expanded_from = []
                                    e.expanded_from.append(t.value)
                                #print "\nExpanding macro", m, "\ninto", ex, "\nreplacing", tokens[i:j+tokcount]
                                tokens[i:j+tokcount] = ex
                    continue
                elif t.value == '__LINE__':
                    t.type = self.t_INTEGER
                    t.value = self.t_INTEGER_TYPE(t.lineno)
                elif t.value == '__COUNTER__':
                    t.type = self.t_INTEGER
                    t.value = self.t_INTEGER_TYPE(self.countermacro)
                    self.countermacro += 1
                
            i += 1
        return tokens

    # ----------------------------------------------------------------------    
    # evalexpr()
    # 
    # Evaluate an expression token sequence for the purposes of evaluating
    # integral expressions.
    # ----------------------------------------------------------------------

    def evalexpr(self,tokens):
        """Evaluate an expression token sequence for the purposes of evaluating
        integral expressions."""
        if not tokens:
            self.on_error('unknown', 0, "Empty expression")
            return (0, None)
        # tokens = tokenize(line)
        # Search for defined macros
        evalfuncts = {'defined' : lambda x: True}
        evalvars = {}
        i = 0
        while i < len(tokens):
            if tokens[i].type == self.t_ID and tokens[i].value == 'defined':
                j = i + 1
                needparen = False
                result = "0L"
                while j < len(tokens):
                    if tokens[j].type in self.t_WS:
                        j += 1
                        continue
                    elif tokens[j].type == self.t_ID:
                        if tokens[j].value in self.macros:
                            result = "1L"
                        else:
                            repl = self.on_unknown_macro_in_defined_expr(tokens[j])
                            if repl is None:
                                # Add this identifier to a dictionary of variables
                                evalvars[tokens[j].value] = 0
                                result = 'defined('+tokens[j].value+')'
                            else:
                                result = "1L" if repl else "0L"
                        if not needparen: break
                    elif tokens[j].value == '(':
                        needparen = True
                    elif tokens[j].value == ')':
                        break
                    else:
                        self.on_error(tokens[i].source,tokens[i].lineno,"Malformed defined()")
                    j += 1
                if result.startswith('defined'):
                    tokens[i].type = self.t_ID
                    tokens[i].value = result
                else:
                    tokens[i].type = self.t_INTEGER
                    tokens[i].value = self.t_INTEGER_TYPE(result)
                del tokens[i+1:j+1]
            i += 1
        tokens = self.expand_macros(tokens)
        if not tokens:
            return (0, None)
        for i,t in enumerate(tokens):
            if t.type == self.t_ID:
                repl = self.on_unknown_macro_in_expr(copy.copy(t))
                if repl is None:
                    # Add this identifier to a dictionary of variables
                    evalvars[t.value] = 0
                else:
                    tokens[i] = t = repl
            if t.type == self.t_INTEGER:
                tokens[i] = copy.copy(t)
                # Strip off any trailing suffixes
                tokens[i].value = str(tokens[i].value)
                while tokens[i].value[-1] not in "0123456789abcdefABCDEF":
                    tokens[i].value = tokens[i].value[:-1]
                if sys.version_info.major >= 3:
                    if len(tokens[i].value) > 1 and tokens[i].value[0] == '0' and tokens[i].value[1] >= '0' and tokens[i].value[1] <= '7':
                        tokens[i].value = '0o' + tokens[i].value[1:]
            elif t.type == self.t_COLON:
                # Find the expression before the colon
                cs = ce = i - 1
                while cs > 0 and tokens[cs].type in self.t_WS:
                    cs -= 1
                if cs > 0 and tokens[cs].value == ')':
                    cs -= 1
                    brackets = 1
                    while cs > 0:
                        if tokens[cs].value == ')':
                            brackets += 1
                        elif tokens[cs].value == '(':
                            brackets -= 1
                            if brackets == 0:
                                break
                        cs -= 1
                while cs > 0 and tokens[cs].type != self.t_TERNARY:
                    cs -= 1
                ternary = cs
                cs += 1
                # Find the expression before the ternary
                es = ee = ternary - 1
                while es > 0 and tokens[es].type in self.t_WS:
                    es -= 1
                if es > 0 and tokens[es].value == ')':
                    es -= 1
                    brackets = 1
                    while es > 0:
                        if tokens[es].value == ')':
                            brackets += 1
                        elif tokens[es].value == '(':
                            brackets -= 1
                            if brackets == 0:
                                break
                        es -= 1
                else:
                    while es > 0 and tokens[es].type not in self.t_WS:
                        es -= 1
                    if tokens[es].value == '(':
                        es += 1
                # Swap the pre-ternary and post-ternary expressions
                tokens[ternary].value = ' if '
                tokens[i].value = ' else '
                # Note this is identical length
                tokens = tokens[:es] + tokens[cs:ce+1] + tokens[ternary:ternary+1] + tokens[es:ee+1] + tokens[i:]
        
        expr = origexpr = "".join([str(x.value) for x in tokens if x.type not in self.t_COMMENT])
        expr = expr.replace("&&"," and ")
        expr = expr.replace("||"," or ")
        expr = expr.replace("!="," <> ")
        expr = expr.replace("!"," not ")
        expr = expr.replace(" <> ", " != ")
        try:
            result = int(eval(expr, evalfuncts, evalvars))
        except Exception:
            self.on_error(tokens[0].source,tokens[0].lineno,"Couldn't evaluate expression due to " + traceback.format_exc()
            + "\nConverted expression was " + expr + " with evalvars = " + repr(evalvars))
            result = 0
        return (result, tokens) if evalvars else (result, None)

    # ----------------------------------------------------------------------
    # parsegen()
    #
    # Parse an input string
    # ----------------------------------------------------------------------
    def parsegen(self,input,source=None,abssource=None):
        """Parse an input string"""

        # Replace trigraph sequences
        t = trigraph(input)
        lines = self.group_lines(t, source)

        if not source:
            source = ""
            
        self.define("__FILE__ \"%s\"" % source)

        self.source = abssource
        chunk = []
        enable = True
        iftrigger = False
        ifpassthru = False
        class ifstackentry(object):
            def __init__(self,enable,iftrigger,ifpassthru,startlinetoks):
                self.enable = enable
                self.iftrigger = iftrigger
                self.ifpassthru = ifpassthru
                self.rewritten = False
                self.startlinetoks = startlinetoks
        ifstack = []
        # True until any non-whitespace output or anything with effects happens.
        at_front_of_file = True
        # True if auto pragma once still a possibility for this #include
        auto_pragma_once_possible = self.auto_pragma_once_enabled
        # =(MACRO, 0) means #ifndef MACRO or #if !defined(MACRO) seen, =(MACRO,1) means #define MACRO seen
        include_guard = None
        self.on_potential_include_guard(None)

        for x in lines:
            all_whitespace = True
            skip_auto_pragma_once_possible_check = False
            # Handle comments
            for i,tok in enumerate(x):
                if tok.type in self.t_COMMENT:
                    self.on_comment(tok)
            # Skip over whitespace
            for i,tok in enumerate(x):
                if tok.type not in self.t_WS and tok.type not in self.t_COMMENT:
                    all_whitespace = False
                    break
            output_and_expand_line = True
            output_unexpanded_line = False
            if tok.value == '#':
                output_and_expand_line = False
                try:
                    # Preprocessor directive      
                    i += 1
                    while x[i].type in self.t_WS:
                        i += 1                    
                    dirtokens = self.tokenstrip(x[i:])
                    if dirtokens:
                        name = dirtokens[0].value
                        args = self.tokenstrip(dirtokens[1:])
                    else:
                        name = ""
                        args = []
                    
                    if self.debugout is not None:
                        print("%d:%d:%d %s:%d #%s %s" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno, dirtokens[0].value, "".join([tok.value for tok in args])), file = self.debugout)
                        #print(ifstack)

                    handling = self.on_directive_handle(dirtokens[0],args,ifpassthru)
                    if handling == False:
                        pass
                    elif name == 'define':
                        at_front_of_file = False
                        if enable:
                            for tok in self.expand_macros(chunk):
                                yield tok
                            chunk = []
                            if include_guard and include_guard[0] == args[0].value:
                                include_guard = (args[0].value, 1)
                                # If ifpassthru is only turned on due to this include guard, turn it off
                                if ifpassthru and not ifstack[-1].ifpassthru:
                                    ifpassthru = False
                            self.define(args)
                            if self.debugout is not None:
                                print("%d:%d:%d %s:%d      %s" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno, repr(self.macros[args[0].value])), file = self.debugout)
                            if handling is None:
                                for tok in x:
                                    yield tok
                    elif name == 'include':
                        if enable:
                            for tok in self.expand_macros(chunk):
                                yield tok
                            chunk = []
                            oldfile = self.macros['__FILE__']
                            for tok in self.include(args):
                                yield tok
                            self.macros['__FILE__'] = oldfile
                            self.source = abssource
                    elif name == 'undef':
                        at_front_of_file = False
                        if enable:
                            for tok in self.expand_macros(chunk):
                                yield tok
                            chunk = []
                            self.undef(args)
                            if handling is None:
                                for tok in x:
                                    yield tok
                    elif name == 'ifdef':
                        at_front_of_file = False
                        ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                        if enable:
                            ifpassthru = False
                            if not args[0].value in self.macros:
                                res = self.on_unknown_macro_in_defined_expr(args[0])
                                if res is None:
                                    ifpassthru = True
                                    ifstack[-1].rewritten = True
                                    raise OutputDirective()
                                elif res is True:
                                    iftrigger = True
                                else:
                                    enable = False
                                    iftrigger = False
                            else:
                                iftrigger = True
                    elif name == 'ifndef':
                        if not ifstack and at_front_of_file:
                            self.on_potential_include_guard(args[0].value)
                            include_guard = (args[0].value, 0)
                        at_front_of_file = False
                        ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                        if enable:
                            ifpassthru = False
                            if args[0].value in self.macros:
                                enable = False
                                iftrigger = False
                            else:
                                res = self.on_unknown_macro_in_defined_expr(args[0])
                                if res is None:
                                    ifpassthru = True
                                    ifstack[-1].rewritten = True
                                    raise OutputDirective()
                                elif res is True:
                                    enable = False
                                    iftrigger = False
                                else:
                                    iftrigger = True
                    elif name == 'if':
                        if not ifstack and at_front_of_file:
                            if args[0].value == '!' and args[1].value == 'defined':
                                n = 2
                                if args[n].value == '(': n += 1
                                self.on_potential_include_guard(args[n].value)
                                include_guard = (args[n].value, 0)
                        at_front_of_file = False
                        ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                        if enable:
                            ifpassthru = False
                            result, rewritten = self.evalexpr(args)
                            if rewritten is not None:
                                x = x[:i+2] + rewritten + [x[-1]]
                                x[i+1] = copy.copy(x[i+1])
                                x[i+1].type = self.t_SPACE
                                x[i+1].value = ' '
                                ifpassthru = True
                                ifstack[-1].rewritten = True
                                raise OutputDirective()
                            if not result:
                                enable = False
                                iftrigger = False
                            else:
                                iftrigger = True
                    elif name == 'elif':
                        at_front_of_file = False
                        if ifstack:
                            if ifstack[-1].enable:     # We only pay attention if outer "if" allows this
                                if enable and not ifpassthru:         # If already true, we flip enable False
                                    enable = False
                                elif not iftrigger:   # If False, but not triggered yet, we'll check expression
                                    result, rewritten = self.evalexpr(args)
                                    if rewritten is not None:
                                        enable = True
                                        if not ifpassthru:
                                            # This is a passthru #elif after a False #if, so convert to an #if
                                            x[i].value = 'if'
                                        x = x[:i+2] + rewritten + [x[-1]]
                                        x[i+1] = copy.copy(x[i+1])
                                        x[i+1].type = self.t_SPACE
                                        x[i+1].value = ' '
                                        ifpassthru = True
                                        ifstack[-1].rewritten = True
                                        raise OutputDirective()
                                    if ifpassthru:
                                        # If this elif can only ever be true, simulate that
                                        if result:
                                            newtok = copy.copy(x[i+3])
                                            newtok.type = self.t_INTEGER
                                            newtok.value = self.t_INTEGER_TYPE(result)
                                            x = x[:i+2] + [newtok] + [x[-1]]
                                            raise OutputDirective()
                                        # Otherwise elide
                                        enable = False
                                    elif result:
                                        enable  = True
                                        iftrigger = True
                        else:
                            self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #elif")
                            
                    elif name == 'else':
                        at_front_of_file = False
                        if ifstack:
                            if ifstack[-1].enable:
                                if ifpassthru:
                                    enable = True
                                    raise OutputDirective()
                                if enable:
                                    enable = False
                                elif not iftrigger:
                                    enable = True
                                    iftrigger = True
                        else:
                            self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #else")

                    elif name == 'endif':
                        at_front_of_file = False
                        if ifstack:
                            oldifstackentry = ifstack.pop()
                            enable = oldifstackentry.enable
                            iftrigger = oldifstackentry.iftrigger
                            ifpassthru = oldifstackentry.ifpassthru
                            if self.debugout is not None:
                                print("%d:%d:%d %s:%d      (%s:%d %s)" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno,
                                    oldifstackentry.startlinetoks[0].source, oldifstackentry.startlinetoks[0].lineno, "".join([n.value for n in oldifstackentry.startlinetoks])), file = self.debugout)
                            skip_auto_pragma_once_possible_check = True
                            if oldifstackentry.rewritten:
                                raise OutputDirective()
                        else:
                            self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #endif")
                    elif name == 'pragma' and args[0].value == 'once':
                        if enable:
                            self.include_once[self.source] = None
                    elif enable:
                        # Unknown preprocessor directive
                        output_unexpanded_line = (self.on_directive_unknown(dirtokens[0], args, ifpassthru) is None)

                except OutputDirective:
                    output_unexpanded_line = True

            # If there is ever any non-whitespace output outside an include guard, auto pragma once is not possible
            if not skip_auto_pragma_once_possible_check and auto_pragma_once_possible and not ifstack and not all_whitespace:
                auto_pragma_once_possible = False
                if self.debugout is not None:
                    print("%d:%d:%d %s:%d Determined that #include \"%s\" is not entirely wrapped in an include guard macro, disabling auto-applying #pragma once" % (enable, iftrigger, ifpassthru, x[0].source, x[0].lineno, self.source), file = self.debugout)
                
            if output_and_expand_line or output_unexpanded_line:
                if not all_whitespace:
                    at_front_of_file = False

                # Normal text
                if enable:
                    if output_and_expand_line:
                        chunk.extend(x)
                    elif output_unexpanded_line:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        for tok in x:
                            yield tok
                else:
                    # Need to extend with the same number of blank lines
                    i = 0
                    while i < len(x):
                        if x[i].type not in self.t_WS:
                            del x[i]
                        else:
                            i += 1
                    chunk.extend(x)

        for tok in self.expand_macros(chunk):
            yield tok
        chunk = []
        for i in ifstack:
            self.on_error(i.startlinetoks[0].source, i.startlinetoks[0].lineno, "Unterminated " + "".join([n.value for n in i.startlinetoks]))
        if auto_pragma_once_possible and include_guard and include_guard[1] == 1:
            if self.debugout is not None:
                print("%d:%d:%d %s:%d Determined that #include \"%s\" is entirely wrapped in an include guard macro called %s, auto-applying #pragma once" % (enable, iftrigger, ifpassthru, self.source, 0, self.source, include_guard[0]), file = self.debugout)
            self.include_once[self.source] = include_guard[0]
        

    # ----------------------------------------------------------------------
    # include()
    #
    # Implementation of file-inclusion
    # ----------------------------------------------------------------------

    def include(self,tokens):
        """Implementation of file-inclusion"""
        # Try to extract the filename and then process an include file
        if not tokens:
            return
        if tokens:
            if tokens[0].value != '<' and tokens[0].type != self.t_STRING:
                tokens = self.tokenstrip(self.expand_macros(tokens))

            is_system_include = False
            if tokens[0].value == '<':
                is_system_include = True
                # Include <...>
                i = 1
                while i < len(tokens):
                    if tokens[i].value == '>':
                        break
                    i += 1
                else:
                    self.on_error(tokens[0].source,tokens[0].lineno,"Malformed #include <...>")
                    return
                filename = "".join([x.value for x in tokens[1:i]])
                path = self.path
            elif tokens[0].type == self.t_STRING:
                filename = tokens[0].value[1:-1]
                path = self.temp_path + self.path
            else:
                self.on_error(tokens[0].source,tokens[0].lineno,"Malformed #include statement")
                return
        while True:
            #print path
            for p in path:
                iname = os.path.join(p,filename)
                fulliname = os.path.abspath(iname)
                if fulliname in self.include_once:
                    if self.debugout is not None:
                        print("x:x:x x:x #include \"%s\" skipped as already seen" % (fulliname), file = self.debugout)
                    return
                try:
                    ih = open(fulliname,"r")
                    data = ih.read()
                    ih.close()
                    dname = os.path.dirname(fulliname)
                    if dname:
                        self.temp_path.insert(0,dname)
                    for tok in self.parsegen(data,filename,fulliname):
                        yield tok
                    if dname:
                        del self.temp_path[0]
                    return
                except IOError:
                    pass
            else:
                p = self.on_include_not_found(is_system_include,self.temp_path[0] if self.temp_path else '',filename)
                if p is None:
                    return
                path.append(p)

    # ----------------------------------------------------------------------
    # define()
    #
    # Define a new macro
    # ----------------------------------------------------------------------

    def define(self,tokens):
        """Define a new macro"""
        if isinstance(tokens,STRING_TYPES):
            tokens = self.tokenize(tokens)
        else:
            tokens = [copy.copy(tok) for tok in tokens]

        linetok = tokens
        try:
            name = linetok[0]
            if len(linetok) > 1:
                mtype = linetok[1]
            else:
                mtype = None
            if not mtype:
                m = Macro(name.value,[])
                self.macros[name.value] = m
            elif mtype.type in self.t_WS:
                # A normal macro
                m = Macro(name.value,self.tokenstrip(linetok[2:]))
                self.macros[name.value] = m
            elif mtype.value == '(':
                # A macro with arguments
                tokcount, args, positions = self.collect_args(linetok[1:])
                variadic = False
                for a in args:
                    if variadic:
                        self.on_error(name.source,name.lineno,"No more arguments may follow a variadic argument")
                        break
                    astr = "".join([str(_i.value) for _i in a])
                    if astr == "...":
                        variadic = True
                        a[0].type = self.t_ID
                        a[0].value = '__VA_ARGS__'
                        variadic = True
                        del a[1:]
                        continue
                    elif astr[-3:] == "..." and a[0].type == self.t_ID:
                        variadic = True
                        del a[1:]
                        # If, for some reason, "." is part of the identifier, strip off the name for the purposes
                        # of macro expansion
                        if a[0].value[-3:] == '...':
                            a[0].value = a[0].value[:-3]
                        continue
                    # Empty arguments are permitted
                    if len(a) == 0 and len(args) == 1:
                        continue
                    if len(a) > 1 or a[0].type != self.t_ID:
                        self.on_error(a.source,a.lineno,"Invalid macro argument")
                        break
                else:
                    mvalue = self.tokenstrip(linetok[1+tokcount:])
                    i = 0
                    while i < len(mvalue):
                        if i+1 < len(mvalue):
                            if mvalue[i].type in self.t_WS and mvalue[i+1].value == '##':
                                del mvalue[i]
                                continue
                            elif mvalue[i].value == '##' and mvalue[i+1].type in self.t_WS:
                                del mvalue[i+1]
                        i += 1
                    m = Macro(name.value,mvalue,[x[0].value for x in args] if args != [[]] else [],variadic)
                    self.macro_prescan(m)
                    self.macros[name.value] = m
            else:
                self.on_error(name.source,name.lineno,"Bad macro definition")
        #except LookupError:
        #    print("Bad macro definition")
        except:
            raise

    # ----------------------------------------------------------------------
    # undef()
    #
    # Undefine a macro
    # ----------------------------------------------------------------------

    def undef(self,tokens):
        """Undefine a macro"""
        if isinstance(tokens,STRING_TYPES):
            tokens = self.tokenize(tokens)
        id = tokens[0].value
        try:
            del self.macros[id]
        except LookupError:
            pass

    # ----------------------------------------------------------------------
    # parse()
    #
    # Parse input text.
    # ----------------------------------------------------------------------
    def parse(self,input,source=None,ignore={}):
        """Parse input text."""
        if isinstance(input, FILE_TYPES):
            if source is None:
                source = input.name
            input = input.read()
        self.ignore = ignore
        self.parser = self.parsegen(input,source,os.path.abspath(source) if source else None)
        if source is not None:
            dname = os.path.dirname(source)
            self.temp_path.insert(0,dname)
        
    # ----------------------------------------------------------------------
    # token()
    #
    # Method to return individual tokens
    # ----------------------------------------------------------------------
    def token(self):
        """Method to return individual tokens"""
        try:
            while True:
                tok = next(self.parser)
                if tok.type not in self.ignore:
                    return tok
        except StopIteration:
            self.parser = None
            return None
            
    def write(self, oh=sys.stdout):
        """Calls token() repeatedly, expanding tokens to their text and writing to the file like stream oh"""
        lastlineno = 0
        lastsource = None
        done = False
        blankacc = []
        blanklines = 0
        while not done:
            emitlinedirective = False
            toks = []
            all_ws = True
            # Accumulate a line
            while not done:
                tok = self.token()
                if not tok:
                    done = True
                    break
                toks.append(tok)
                if tok.value[0] == '\n':
                    break
                if tok.type not in self.t_WS:
                    all_ws = False
            if not toks:
                break
            if all_ws:
                # Remove preceding whitespace so it becomes just a LF
                if len(toks) > 1:
                    tok = toks[-1]
                    toks = [ tok ]
                blankacc.append(toks)
                blanklines += toks[0].value.count('\n')
                continue
            # The line in toks is not all whitespace
            emitlinedirective = (blanklines > 6) and self.line_directive is not None
            if hasattr(toks[0], 'source'):
                if lastsource is None:
                    lastsource = toks[0].source
                elif lastsource != toks[0].source:
                    emitlinedirective = True
                    lastsource = toks[0].source
            # Replace consecutive whitespace in output with a single space except at any indent
            first_ws = None
            for n in xrange(len(toks)-1, -1, -1):
                tok = toks[n]
                if first_ws is None:
                    if tok.type in self.t_SPACE or len(tok.value) == 0:
                        first_ws = n
                else:
                    if tok.type not in self.t_SPACE and len(tok.value) > 0:
                        m = n + 1
                        while m != first_ws:
                            del toks[m]
                            first_ws -= 1
                        first_ws = None
                        # Collapse a token of many whitespace into single
                        if toks[m].value[0] == ' ':
                            toks[m].value = ' '
            if not emitlinedirective:
                newlinesneeded = toks[0].lineno - lastlineno - 1
                if newlinesneeded > 6 and self.line_directive is not None:
                    emitlinedirective = True
                else:
                    while newlinesneeded > 0:
                        oh.write('\n')
                        newlinesneeded -= 1
            lastlineno = toks[0].lineno
            if emitlinedirective and self.line_directive is not None:
                oh.write(self.line_directive + ' ' + str(lastlineno) + ('' if lastsource is None else (' "' + lastsource + '"' )) + '\n')
            #elif blanklines > 0:
            #    for line in blankacc:
            #        for tok in line:
            #            oh.write(tok.value)
            blankacc = []
            blanklines = 0
            #print toks[0].lineno, 
            for tok in toks:
                #print tok.value,
                oh.write(tok.value)
            #print ''

if __name__ == "__main__":
    import doctest
    doctest.testmod()

</code></pre>
  </div>

  </header>

  <section id="section-items">


    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="pcpp.OutputDirective" class="name">class <span class="ident">OutputDirective</span></p>
      
  
    <div class="desc"><p>Raise this exception to abort processing of a preprocessor directive and
to instead output it as is into the output</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.OutputDirective', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.OutputDirective" class="source">
    <pre><code>class OutputDirective(Exception):
    """Raise this exception to abort processing of a preprocessor directive and
    to instead output it as is into the output"""
    pass
</code></pre>
  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#pcpp.OutputDirective">OutputDirective</a></li>
          <li>exceptions.Exception</li>
          <li>exceptions.BaseException</li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Class variables</h3>
            <div class="item">
            <p id="pcpp.OutputDirective.args" class="name">var <span class="ident">args</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="pcpp.OutputDirective.message" class="name">var <span class="ident">message</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="pcpp.Preprocessor" class="name">class <span class="ident">Preprocessor</span></p>
      
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor" class="source">
    <pre><code>class Preprocessor(PreprocessorHooks):    
    def __init__(self,lexer=None):
        super(Preprocessor, self).__init__()
        if lexer is None:
            import ply.lex as lex
            lexer = lex.lex()
        self.lexer = lexer
        self.macros = { }
        self.path = []
        self.temp_path = []
        self.include_once = {}
        self.return_code = 0
        self.debugout = None
        self.auto_pragma_once_enabled = True
        self.line_directive = '#line'

        # Probe the lexer for selected tokens
        self.__lexprobe()

        tm = time.localtime()
        self.define("__DATE__ \"%s\"" % time.strftime("%b %d %Y",tm))
        self.define("__TIME__ \"%s\"" % time.strftime("%H:%M:%S",tm))
        self.define("__PCPP__ 1")
        self.countermacro = 0
        self.parser = None

    # -----------------------------------------------------------------------------
    # tokenize()
    #
    # Utility function. Given a string of text, tokenize into a list of tokens
    # -----------------------------------------------------------------------------

    def tokenize(self,text):
        """Utility function. Given a string of text, tokenize into a list of tokens"""
        tokens = []
        self.lexer.input(text)
        while True:
            tok = self.lexer.token()
            if not tok: break
            tokens.append(tok)
        return tokens

    # ----------------------------------------------------------------------
    # __lexprobe()
    #
    # This method probes the preprocessor lexer object to discover
    # the token types of symbols that are important to the preprocessor.
    # If this works right, the preprocessor will simply "work"
    # with any suitable lexer regardless of how tokens have been named.
    # ----------------------------------------------------------------------

    def __lexprobe(self):

        # Determine the token type for identifiers
        self.lexer.input("identifier")
        tok = self.lexer.token()
        if not tok or tok.value != "identifier":
            print("Couldn't determine identifier type")
        else:
            self.t_ID = tok.type

        # Determine the token type for integers
        self.lexer.input("12345")
        tok = self.lexer.token()
        if not tok or int(tok.value) != 12345:
            print("Couldn't determine integer type")
        else:
            self.t_INTEGER = tok.type
            self.t_INTEGER_TYPE = type(tok.value)

        # Determine the token type for strings enclosed in double quotes
        self.lexer.input("\"filename\"")
        tok = self.lexer.token()
        if not tok or tok.value != "\"filename\"":
            print("Couldn't determine string type")
        else:
            self.t_STRING = tok.type

        # Determine the token type for whitespace--if any
        self.lexer.input("  ")
        tok = self.lexer.token()
        if not tok or tok.value != "  ":
            self.t_SPACE = None
        else:
            self.t_SPACE = tok.type

        # Determine the token type for newlines
        self.lexer.input("\n")
        tok = self.lexer.token()
        if not tok or tok.value != "\n":
            self.t_NEWLINE = None
            print("Couldn't determine token for newlines")
        else:
            self.t_NEWLINE = tok.type

        self.t_WS = (self.t_SPACE, self.t_NEWLINE)

        self.lexer.input("##")
        tok = self.lexer.token()
        if not tok or tok.value != "##":
            print("Couldn't determine token for token pasting operator")
        else:
            self.t_DPOUND = tok.type

        self.lexer.input("?")
        tok = self.lexer.token()
        if not tok or tok.value != "?":
            print("Couldn't determine token for ternary operator")
        else:
            self.t_TERNARY = tok.type

        self.lexer.input(":")
        tok = self.lexer.token()
        if not tok or tok.value != ":":
            print("Couldn't determine token for ternary operator")
        else:
            self.t_COLON = tok.type

        self.lexer.input("/* comment */")
        tok = self.lexer.token()
        if not tok or tok.value != "/* comment */":
            print("Couldn't determine comment type")
        else:
            self.t_COMMENT1 = tok.type

        self.lexer.input("// comment")
        tok = self.lexer.token()
        if not tok or tok.value != "// comment":
            print("Couldn't determine comment type")
        else:
            self.t_COMMENT2 = tok.type
            
        self.t_COMMENT = (self.t_COMMENT1, self.t_COMMENT2)

        # Check for other characters used by the preprocessor
        chars = [ '<','>','#','##','\\','(',')',',','.']
        for c in chars:
            self.lexer.input(c)
            tok = self.lexer.token()
            if not tok or tok.value != c:
                print("Unable to lex '%s' required for preprocessor" % c)

    # ----------------------------------------------------------------------
    # add_path()
    #
    # Adds a search path to the preprocessor.  
    # ----------------------------------------------------------------------

    def add_path(self,path):
        """Adds a search path to the preprocessor. """
        self.path.append(path)

    # ----------------------------------------------------------------------
    # group_lines()
    #
    # Given an input string, this function splits it into lines.  Trailing whitespace
    # is removed.   Any line ending with \ is grouped with the next line.  This
    # function forms the lowest level of the preprocessor---grouping into text into
    # a line-by-line format.
    # ----------------------------------------------------------------------

    def group_lines(self,input,source):
        """Given an input string, this function splits it into lines.  Trailing whitespace
        is removed.   Any line ending with \ is grouped with the next line.  This
        function forms the lowest level of the preprocessor---grouping into text into
        a line-by-line format.
        """
        lex = self.lexer.clone()
        lines = [x.rstrip() for x in input.splitlines()]
        for i in xrange(len(lines)):
            j = i+1
            while lines[i].endswith('\\') and (j < len(lines)):
                lines[i] = lines[i][:-1]+lines[j]
                lines[j] = ""
                j += 1

        input = "\n".join(lines)
        lex.input(input)
        lex.lineno = 1

        current_line = []
        while True:
            tok = lex.token()
            if not tok:
                break
            tok.source = source
            current_line.append(tok)
            if tok.type in self.t_WS and '\n' in tok.value:
                yield current_line
                current_line = []

        if current_line:
            nltok = copy.copy(current_line[-1])
            nltok.type = self.t_NEWLINE
            nltok.value = '\n'
            current_line.append(nltok)
            yield current_line

    # ----------------------------------------------------------------------
    # tokenstrip()
    # 
    # Remove leading/trailing whitespace tokens from a token list
    # ----------------------------------------------------------------------

    def tokenstrip(self,tokens):
        """Remove leading/trailing whitespace tokens from a token list"""
        i = 0
        while i < len(tokens) and tokens[i].type in self.t_WS:
            i += 1
        del tokens[:i]
        i = len(tokens)-1
        while i >= 0 and tokens[i].type in self.t_WS:
            i -= 1
        del tokens[i+1:]
        return tokens


    # ----------------------------------------------------------------------
    # collect_args()
    #
    # Collects comma separated arguments from a list of tokens.   The arguments
    # must be enclosed in parenthesis.  Returns a tuple (tokencount,args,positions)
    # where tokencount is the number of tokens consumed, args is a list of arguments,
    # and positions is a list of integers containing the starting index of each
    # argument.  Each argument is represented by a list of tokens.
    #
    # When collecting arguments, leading and trailing whitespace is removed
    # from each argument.  
    #
    # This function properly handles nested parenthesis and commas---these do not
    # define new arguments.
    # ----------------------------------------------------------------------

    def collect_args(self,tokenlist,ignore_errors=False):
        """Collects comma separated arguments from a list of tokens.   The arguments
        must be enclosed in parenthesis.  Returns a tuple (tokencount,args,positions)
        where tokencount is the number of tokens consumed, args is a list of arguments,
        and positions is a list of integers containing the starting index of each
        argument.  Each argument is represented by a list of tokens.
        
        When collecting arguments, leading and trailing whitespace is removed
        from each argument.  
        
        This function properly handles nested parenthesis and commas---these do not
        define new arguments."""
        args = []
        positions = []
        current_arg = []
        nesting = 1
        tokenlen = len(tokenlist)
    
        # Search for the opening '('.
        i = 0
        while (i < tokenlen) and (tokenlist[i].type in self.t_WS):
            i += 1

        if (i < tokenlen) and (tokenlist[i].value == '('):
            positions.append(i+1)
        else:
            if not ignore_errors:
                self.on_error(tokenlist[0].source,tokenlist[0].lineno,"Missing '(' in macro arguments")
            return 0, [], []

        i += 1

        while i < tokenlen:
            t = tokenlist[i]
            if t.value == '(':
                current_arg.append(t)
                nesting += 1
            elif t.value == ')':
                nesting -= 1
                if nesting == 0:
                    args.append(self.tokenstrip(current_arg))
                    positions.append(i)
                    return i+1,args,positions
                current_arg.append(t)
            elif t.value == ',' and nesting == 1:
                args.append(self.tokenstrip(current_arg))
                positions.append(i+1)
                current_arg = []
            else:
                current_arg.append(t)
            i += 1
    
        # Missing end argument
        if not ignore_errors:
            self.on_error(tokenlist[-1].source,tokenlist[-1].lineno,"Missing ')' in macro arguments")
        return 0, [],[]

    # ----------------------------------------------------------------------
    # macro_prescan()
    #
    # Examine the macro value (token sequence) and identify patch points
    # This is used to speed up macro expansion later on---we'll know
    # right away where to apply patches to the value to form the expansion
    # ----------------------------------------------------------------------
    
    def macro_prescan(self,macro):
        """Examine the macro value (token sequence) and identify patch points
        This is used to speed up macro expansion later on---we'll know
        right away where to apply patches to the value to form the expansion"""
        macro.patch     = []             # Standard macro arguments 
        macro.str_patch = []             # String conversion expansion
        macro.var_comma_patch = []       # Variadic macro comma patch
        i = 0
        #print "BEFORE", macro.value
        while i < len(macro.value):
            if macro.value[i].type == self.t_ID and macro.value[i].value in macro.arglist:
                argnum = macro.arglist.index(macro.value[i].value)
                # Conversion of argument to a string
                j = i - 1
                while j >= 0 and macro.value[j].type in self.t_WS:
                    j -= 1
                if j >= 0 and macro.value[j].value == '#':
                    macro.value[i] = copy.copy(macro.value[i])
                    macro.value[i].type = self.t_STRING
                    while i > j:
                        del macro.value[j]
                        i -= 1
                    macro.str_patch.append((argnum,i))
                    continue
                # Concatenation
                elif (i > 0 and macro.value[i-1].value == '##'):
                    macro.patch.append(('t',argnum,i))
                    i += 1
                    continue
                elif ((i+1) < len(macro.value) and macro.value[i+1].value == '##'):
                    macro.patch.append(('t',argnum,i))
                    i += 1
                    continue
                # Standard expansion
                else:
                    macro.patch.append(('e',argnum,i))
            elif macro.value[i].value == '##':
                if macro.variadic and (i > 0) and (macro.value[i-1].value == ',') and \
                        ((i+1) < len(macro.value)) and (macro.value[i+1].type == self.t_ID) and \
                        (macro.value[i+1].value == macro.vararg):
                    macro.var_comma_patch.append(i-1)
            i += 1
        macro.patch.sort(key=lambda x: x[2],reverse=True)
        #print "AFTER", macro.value

    # ----------------------------------------------------------------------
    # macro_expand_args()
    #
    # Given a Macro and list of arguments (each a token list), this method
    # returns an expanded version of a macro.  The return value is a token sequence
    # representing the replacement macro tokens
    # ----------------------------------------------------------------------

    def macro_expand_args(self,macro,args):
        """Given a Macro and list of arguments (each a token list), this method
        returns an expanded version of a macro.  The return value is a token sequence
        representing the replacement macro tokens"""
        # Make a copy of the macro token sequence
        rep = [copy.copy(_x) for _x in macro.value]

        # Make string expansion patches.  These do not alter the length of the replacement sequence
        str_expansion = {}
        for argnum, i in macro.str_patch:
            if argnum not in str_expansion:
                # Strip all non-space whitespace before stringization
                tokens = copy.copy(args[argnum])
                for j in xrange(len(tokens)):
                    if tokens[j].type in self.t_WS:
                        tokens[j].value = ' '
                # Collapse all multiple whitespace too
                j = 0
                while j < len(tokens) - 1:
                    if tokens[j].type in self.t_WS and tokens[j+1].type in self.t_WS:
                        del tokens[j+1]
                    else:
                        j += 1
                str = "".join([x.value for x in tokens])
                str = str.replace("\\","\\\\").replace('"', '\\"')
                str_expansion[argnum] = '"' + str + '"'
            rep[i] = copy.copy(rep[i])
            rep[i].value = str_expansion[argnum]

        # Make the variadic macro comma patch.  If the variadic macro argument is empty, we get rid
        comma_patch = False
        if macro.variadic and not args[-1]:
            for i in macro.var_comma_patch:
                rep[i] = None
                comma_patch = True

        # Make all other patches.   The order of these matters.  It is assumed that the patch list
        # has been sorted in reverse order of patch location since replacements will cause the
        # size of the replacement sequence to expand from the patch point.
        
        expanded = { }
        #print "***", macro
        #print macro.patch
        for ptype, argnum, i in macro.patch:
            # Concatenation.   Argument is left unexpanded
            if ptype == 't':
                rep[i:i+1] = args[argnum]
            # Normal expansion.  Argument is macro expanded first
            elif ptype == 'e':
                if argnum not in expanded:
                    expanded[argnum] = self.expand_macros(args[argnum])
                rep[i:i+1] = expanded[argnum]

        # Get rid of removed comma if necessary
        if comma_patch:
            rep = [_i for _i in rep if _i]
            
        # Do a token concatenation pass, stitching any tokens separated by ## into a single token
        while len(rep) and rep[0].type == self.t_DPOUND:
            del rep[0]
        while len(rep) and rep[-1].type == self.t_DPOUND:
            del rep[-1]
        i = 1
        while i < len(rep) - 1:
            if rep[i].type == self.t_DPOUND:
                j = i + 1
                while rep[j].type == self.t_DPOUND:
                    j += 1
                rep[i-1].type = self.t_ID
                rep[i-1].value += rep[j].value
                while j >= i:
                    del rep[i]
                    j -= 1
            else:
                i += 1

        #print rep
        return rep


    # ----------------------------------------------------------------------
    # expand_macros()
    #
    # Given a list of tokens, this function performs macro expansion.
    # ----------------------------------------------------------------------

    def expand_macros(self,tokens,expanding_from=[]):
        """Given a list of tokens, this function performs macro expansion."""
        # Each token needs to track from which macros it has been expanded from to prevent recursion
        for tok in tokens:
            if not hasattr(tok, 'expanded_from'):
                tok.expanded_from = []
        i = 0
        #print "*** EXPAND MACROS in", "".join([t.value for t in tokens]), "expanding_from=", expanding_from
        #print tokens
        #print [(t.value, t.expanded_from) for t in tokens]
        while i < len(tokens):
            t = tokens[i]
            if t.type == self.t_ID:
                if t.value in self.macros and t.value not in t.expanded_from and t.value not in expanding_from:
                    # Yes, we found a macro match
                    m = self.macros[t.value]
                    if m.arglist is None:
                        # A simple macro
                        rep = [copy.copy(_x) for _x in m.value]
                        ex = self.expand_macros(rep, expanding_from + [t.value])
                        #print "\nExpanding macro", m, "\ninto", ex, "\nreplacing", tokens[i:i+1]
                        for e in ex:
                            e.source = t.source
                            e.lineno = t.lineno
                            if not hasattr(e, 'expanded_from'):
                                e.expanded_from = []
                            e.expanded_from.append(t.value)
                        tokens[i:i+1] = ex
                    else:
                        # A macro with arguments
                        j = i + 1
                        while j < len(tokens) and (tokens[j].type in self.t_WS or tokens[j].type in self.t_COMMENT):
                            j += 1
                        # A function like macro without an invocation list is to be ignored
                        if j == len(tokens) or tokens[j].value != '(':
                            i = j
                        else:
                            tokcount,args,positions = self.collect_args(tokens[j:], True)
                            if tokcount == 0:
                                # Unclosed parameter list, just bail out
                                break
                            if (not m.variadic
                                # A no arg or single arg consuming macro is permitted to be expanded with nothing
                                and (args != [[]] or len(m.arglist) > 1)
                                and len(args) !=  len(m.arglist)):
                                self.on_error(t.source,t.lineno,"Macro %s requires %d arguments but was passed %d" % (t.value,len(m.arglist),len(args)))
                                i = j + tokcount
                            elif m.variadic and len(args) < len(m.arglist)-1:
                                if len(m.arglist) > 2:
                                    self.on_error(t.source,t.lineno,"Macro %s must have at least %d arguments" % (t.value, len(m.arglist)-1))
                                else:
                                    self.on_error(t.source,t.lineno,"Macro %s must have at least %d argument" % (t.value, len(m.arglist)-1))
                                i = j + tokcount
                            else:
                                if m.variadic:
                                    if len(args) == len(m.arglist)-1:
                                        args.append([])
                                    else:
                                        args[len(m.arglist)-1] = tokens[j+positions[len(m.arglist)-1]:j+tokcount-1]
                                        del args[len(m.arglist):]
                                else:
                                    # If we called a single arg macro with empty, fake extend args
                                    while len(args) < len(m.arglist):
                                        args.append([])
                                        
                                # Get macro replacement text
                                rep = self.macro_expand_args(m,args)
                                ex = self.expand_macros(rep, expanding_from + [t.value])
                                for e in ex:
                                    e.source = t.source
                                    e.lineno = t.lineno
                                    if not hasattr(e, 'expanded_from'):
                                        e.expanded_from = []
                                    e.expanded_from.append(t.value)
                                #print "\nExpanding macro", m, "\ninto", ex, "\nreplacing", tokens[i:j+tokcount]
                                tokens[i:j+tokcount] = ex
                    continue
                elif t.value == '__LINE__':
                    t.type = self.t_INTEGER
                    t.value = self.t_INTEGER_TYPE(t.lineno)
                elif t.value == '__COUNTER__':
                    t.type = self.t_INTEGER
                    t.value = self.t_INTEGER_TYPE(self.countermacro)
                    self.countermacro += 1
                
            i += 1
        return tokens

    # ----------------------------------------------------------------------    
    # evalexpr()
    # 
    # Evaluate an expression token sequence for the purposes of evaluating
    # integral expressions.
    # ----------------------------------------------------------------------

    def evalexpr(self,tokens):
        """Evaluate an expression token sequence for the purposes of evaluating
        integral expressions."""
        if not tokens:
            self.on_error('unknown', 0, "Empty expression")
            return (0, None)
        # tokens = tokenize(line)
        # Search for defined macros
        evalfuncts = {'defined' : lambda x: True}
        evalvars = {}
        i = 0
        while i < len(tokens):
            if tokens[i].type == self.t_ID and tokens[i].value == 'defined':
                j = i + 1
                needparen = False
                result = "0L"
                while j < len(tokens):
                    if tokens[j].type in self.t_WS:
                        j += 1
                        continue
                    elif tokens[j].type == self.t_ID:
                        if tokens[j].value in self.macros:
                            result = "1L"
                        else:
                            repl = self.on_unknown_macro_in_defined_expr(tokens[j])
                            if repl is None:
                                # Add this identifier to a dictionary of variables
                                evalvars[tokens[j].value] = 0
                                result = 'defined('+tokens[j].value+')'
                            else:
                                result = "1L" if repl else "0L"
                        if not needparen: break
                    elif tokens[j].value == '(':
                        needparen = True
                    elif tokens[j].value == ')':
                        break
                    else:
                        self.on_error(tokens[i].source,tokens[i].lineno,"Malformed defined()")
                    j += 1
                if result.startswith('defined'):
                    tokens[i].type = self.t_ID
                    tokens[i].value = result
                else:
                    tokens[i].type = self.t_INTEGER
                    tokens[i].value = self.t_INTEGER_TYPE(result)
                del tokens[i+1:j+1]
            i += 1
        tokens = self.expand_macros(tokens)
        if not tokens:
            return (0, None)
        for i,t in enumerate(tokens):
            if t.type == self.t_ID:
                repl = self.on_unknown_macro_in_expr(copy.copy(t))
                if repl is None:
                    # Add this identifier to a dictionary of variables
                    evalvars[t.value] = 0
                else:
                    tokens[i] = t = repl
            if t.type == self.t_INTEGER:
                tokens[i] = copy.copy(t)
                # Strip off any trailing suffixes
                tokens[i].value = str(tokens[i].value)
                while tokens[i].value[-1] not in "0123456789abcdefABCDEF":
                    tokens[i].value = tokens[i].value[:-1]
                if sys.version_info.major >= 3:
                    if len(tokens[i].value) > 1 and tokens[i].value[0] == '0' and tokens[i].value[1] >= '0' and tokens[i].value[1] <= '7':
                        tokens[i].value = '0o' + tokens[i].value[1:]
            elif t.type == self.t_COLON:
                # Find the expression before the colon
                cs = ce = i - 1
                while cs > 0 and tokens[cs].type in self.t_WS:
                    cs -= 1
                if cs > 0 and tokens[cs].value == ')':
                    cs -= 1
                    brackets = 1
                    while cs > 0:
                        if tokens[cs].value == ')':
                            brackets += 1
                        elif tokens[cs].value == '(':
                            brackets -= 1
                            if brackets == 0:
                                break
                        cs -= 1
                while cs > 0 and tokens[cs].type != self.t_TERNARY:
                    cs -= 1
                ternary = cs
                cs += 1
                # Find the expression before the ternary
                es = ee = ternary - 1
                while es > 0 and tokens[es].type in self.t_WS:
                    es -= 1
                if es > 0 and tokens[es].value == ')':
                    es -= 1
                    brackets = 1
                    while es > 0:
                        if tokens[es].value == ')':
                            brackets += 1
                        elif tokens[es].value == '(':
                            brackets -= 1
                            if brackets == 0:
                                break
                        es -= 1
                else:
                    while es > 0 and tokens[es].type not in self.t_WS:
                        es -= 1
                    if tokens[es].value == '(':
                        es += 1
                # Swap the pre-ternary and post-ternary expressions
                tokens[ternary].value = ' if '
                tokens[i].value = ' else '
                # Note this is identical length
                tokens = tokens[:es] + tokens[cs:ce+1] + tokens[ternary:ternary+1] + tokens[es:ee+1] + tokens[i:]
        
        expr = origexpr = "".join([str(x.value) for x in tokens if x.type not in self.t_COMMENT])
        expr = expr.replace("&&"," and ")
        expr = expr.replace("||"," or ")
        expr = expr.replace("!="," <> ")
        expr = expr.replace("!"," not ")
        expr = expr.replace(" <> ", " != ")
        try:
            result = int(eval(expr, evalfuncts, evalvars))
        except Exception:
            self.on_error(tokens[0].source,tokens[0].lineno,"Couldn't evaluate expression due to " + traceback.format_exc()
            + "\nConverted expression was " + expr + " with evalvars = " + repr(evalvars))
            result = 0
        return (result, tokens) if evalvars else (result, None)

    # ----------------------------------------------------------------------
    # parsegen()
    #
    # Parse an input string
    # ----------------------------------------------------------------------
    def parsegen(self,input,source=None,abssource=None):
        """Parse an input string"""

        # Replace trigraph sequences
        t = trigraph(input)
        lines = self.group_lines(t, source)

        if not source:
            source = ""
            
        self.define("__FILE__ \"%s\"" % source)

        self.source = abssource
        chunk = []
        enable = True
        iftrigger = False
        ifpassthru = False
        class ifstackentry(object):
            def __init__(self,enable,iftrigger,ifpassthru,startlinetoks):
                self.enable = enable
                self.iftrigger = iftrigger
                self.ifpassthru = ifpassthru
                self.rewritten = False
                self.startlinetoks = startlinetoks
        ifstack = []
        # True until any non-whitespace output or anything with effects happens.
        at_front_of_file = True
        # True if auto pragma once still a possibility for this #include
        auto_pragma_once_possible = self.auto_pragma_once_enabled
        # =(MACRO, 0) means #ifndef MACRO or #if !defined(MACRO) seen, =(MACRO,1) means #define MACRO seen
        include_guard = None
        self.on_potential_include_guard(None)

        for x in lines:
            all_whitespace = True
            skip_auto_pragma_once_possible_check = False
            # Handle comments
            for i,tok in enumerate(x):
                if tok.type in self.t_COMMENT:
                    self.on_comment(tok)
            # Skip over whitespace
            for i,tok in enumerate(x):
                if tok.type not in self.t_WS and tok.type not in self.t_COMMENT:
                    all_whitespace = False
                    break
            output_and_expand_line = True
            output_unexpanded_line = False
            if tok.value == '#':
                output_and_expand_line = False
                try:
                    # Preprocessor directive      
                    i += 1
                    while x[i].type in self.t_WS:
                        i += 1                    
                    dirtokens = self.tokenstrip(x[i:])
                    if dirtokens:
                        name = dirtokens[0].value
                        args = self.tokenstrip(dirtokens[1:])
                    else:
                        name = ""
                        args = []
                    
                    if self.debugout is not None:
                        print("%d:%d:%d %s:%d #%s %s" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno, dirtokens[0].value, "".join([tok.value for tok in args])), file = self.debugout)
                        #print(ifstack)

                    handling = self.on_directive_handle(dirtokens[0],args,ifpassthru)
                    if handling == False:
                        pass
                    elif name == 'define':
                        at_front_of_file = False
                        if enable:
                            for tok in self.expand_macros(chunk):
                                yield tok
                            chunk = []
                            if include_guard and include_guard[0] == args[0].value:
                                include_guard = (args[0].value, 1)
                                # If ifpassthru is only turned on due to this include guard, turn it off
                                if ifpassthru and not ifstack[-1].ifpassthru:
                                    ifpassthru = False
                            self.define(args)
                            if self.debugout is not None:
                                print("%d:%d:%d %s:%d      %s" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno, repr(self.macros[args[0].value])), file = self.debugout)
                            if handling is None:
                                for tok in x:
                                    yield tok
                    elif name == 'include':
                        if enable:
                            for tok in self.expand_macros(chunk):
                                yield tok
                            chunk = []
                            oldfile = self.macros['__FILE__']
                            for tok in self.include(args):
                                yield tok
                            self.macros['__FILE__'] = oldfile
                            self.source = abssource
                    elif name == 'undef':
                        at_front_of_file = False
                        if enable:
                            for tok in self.expand_macros(chunk):
                                yield tok
                            chunk = []
                            self.undef(args)
                            if handling is None:
                                for tok in x:
                                    yield tok
                    elif name == 'ifdef':
                        at_front_of_file = False
                        ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                        if enable:
                            ifpassthru = False
                            if not args[0].value in self.macros:
                                res = self.on_unknown_macro_in_defined_expr(args[0])
                                if res is None:
                                    ifpassthru = True
                                    ifstack[-1].rewritten = True
                                    raise OutputDirective()
                                elif res is True:
                                    iftrigger = True
                                else:
                                    enable = False
                                    iftrigger = False
                            else:
                                iftrigger = True
                    elif name == 'ifndef':
                        if not ifstack and at_front_of_file:
                            self.on_potential_include_guard(args[0].value)
                            include_guard = (args[0].value, 0)
                        at_front_of_file = False
                        ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                        if enable:
                            ifpassthru = False
                            if args[0].value in self.macros:
                                enable = False
                                iftrigger = False
                            else:
                                res = self.on_unknown_macro_in_defined_expr(args[0])
                                if res is None:
                                    ifpassthru = True
                                    ifstack[-1].rewritten = True
                                    raise OutputDirective()
                                elif res is True:
                                    enable = False
                                    iftrigger = False
                                else:
                                    iftrigger = True
                    elif name == 'if':
                        if not ifstack and at_front_of_file:
                            if args[0].value == '!' and args[1].value == 'defined':
                                n = 2
                                if args[n].value == '(': n += 1
                                self.on_potential_include_guard(args[n].value)
                                include_guard = (args[n].value, 0)
                        at_front_of_file = False
                        ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                        if enable:
                            ifpassthru = False
                            result, rewritten = self.evalexpr(args)
                            if rewritten is not None:
                                x = x[:i+2] + rewritten + [x[-1]]
                                x[i+1] = copy.copy(x[i+1])
                                x[i+1].type = self.t_SPACE
                                x[i+1].value = ' '
                                ifpassthru = True
                                ifstack[-1].rewritten = True
                                raise OutputDirective()
                            if not result:
                                enable = False
                                iftrigger = False
                            else:
                                iftrigger = True
                    elif name == 'elif':
                        at_front_of_file = False
                        if ifstack:
                            if ifstack[-1].enable:     # We only pay attention if outer "if" allows this
                                if enable and not ifpassthru:         # If already true, we flip enable False
                                    enable = False
                                elif not iftrigger:   # If False, but not triggered yet, we'll check expression
                                    result, rewritten = self.evalexpr(args)
                                    if rewritten is not None:
                                        enable = True
                                        if not ifpassthru:
                                            # This is a passthru #elif after a False #if, so convert to an #if
                                            x[i].value = 'if'
                                        x = x[:i+2] + rewritten + [x[-1]]
                                        x[i+1] = copy.copy(x[i+1])
                                        x[i+1].type = self.t_SPACE
                                        x[i+1].value = ' '
                                        ifpassthru = True
                                        ifstack[-1].rewritten = True
                                        raise OutputDirective()
                                    if ifpassthru:
                                        # If this elif can only ever be true, simulate that
                                        if result:
                                            newtok = copy.copy(x[i+3])
                                            newtok.type = self.t_INTEGER
                                            newtok.value = self.t_INTEGER_TYPE(result)
                                            x = x[:i+2] + [newtok] + [x[-1]]
                                            raise OutputDirective()
                                        # Otherwise elide
                                        enable = False
                                    elif result:
                                        enable  = True
                                        iftrigger = True
                        else:
                            self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #elif")
                            
                    elif name == 'else':
                        at_front_of_file = False
                        if ifstack:
                            if ifstack[-1].enable:
                                if ifpassthru:
                                    enable = True
                                    raise OutputDirective()
                                if enable:
                                    enable = False
                                elif not iftrigger:
                                    enable = True
                                    iftrigger = True
                        else:
                            self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #else")

                    elif name == 'endif':
                        at_front_of_file = False
                        if ifstack:
                            oldifstackentry = ifstack.pop()
                            enable = oldifstackentry.enable
                            iftrigger = oldifstackentry.iftrigger
                            ifpassthru = oldifstackentry.ifpassthru
                            if self.debugout is not None:
                                print("%d:%d:%d %s:%d      (%s:%d %s)" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno,
                                    oldifstackentry.startlinetoks[0].source, oldifstackentry.startlinetoks[0].lineno, "".join([n.value for n in oldifstackentry.startlinetoks])), file = self.debugout)
                            skip_auto_pragma_once_possible_check = True
                            if oldifstackentry.rewritten:
                                raise OutputDirective()
                        else:
                            self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #endif")
                    elif name == 'pragma' and args[0].value == 'once':
                        if enable:
                            self.include_once[self.source] = None
                    elif enable:
                        # Unknown preprocessor directive
                        output_unexpanded_line = (self.on_directive_unknown(dirtokens[0], args, ifpassthru) is None)

                except OutputDirective:
                    output_unexpanded_line = True

            # If there is ever any non-whitespace output outside an include guard, auto pragma once is not possible
            if not skip_auto_pragma_once_possible_check and auto_pragma_once_possible and not ifstack and not all_whitespace:
                auto_pragma_once_possible = False
                if self.debugout is not None:
                    print("%d:%d:%d %s:%d Determined that #include \"%s\" is not entirely wrapped in an include guard macro, disabling auto-applying #pragma once" % (enable, iftrigger, ifpassthru, x[0].source, x[0].lineno, self.source), file = self.debugout)
                
            if output_and_expand_line or output_unexpanded_line:
                if not all_whitespace:
                    at_front_of_file = False

                # Normal text
                if enable:
                    if output_and_expand_line:
                        chunk.extend(x)
                    elif output_unexpanded_line:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        for tok in x:
                            yield tok
                else:
                    # Need to extend with the same number of blank lines
                    i = 0
                    while i < len(x):
                        if x[i].type not in self.t_WS:
                            del x[i]
                        else:
                            i += 1
                    chunk.extend(x)

        for tok in self.expand_macros(chunk):
            yield tok
        chunk = []
        for i in ifstack:
            self.on_error(i.startlinetoks[0].source, i.startlinetoks[0].lineno, "Unterminated " + "".join([n.value for n in i.startlinetoks]))
        if auto_pragma_once_possible and include_guard and include_guard[1] == 1:
            if self.debugout is not None:
                print("%d:%d:%d %s:%d Determined that #include \"%s\" is entirely wrapped in an include guard macro called %s, auto-applying #pragma once" % (enable, iftrigger, ifpassthru, self.source, 0, self.source, include_guard[0]), file = self.debugout)
            self.include_once[self.source] = include_guard[0]
        

    # ----------------------------------------------------------------------
    # include()
    #
    # Implementation of file-inclusion
    # ----------------------------------------------------------------------

    def include(self,tokens):
        """Implementation of file-inclusion"""
        # Try to extract the filename and then process an include file
        if not tokens:
            return
        if tokens:
            if tokens[0].value != '<' and tokens[0].type != self.t_STRING:
                tokens = self.tokenstrip(self.expand_macros(tokens))

            is_system_include = False
            if tokens[0].value == '<':
                is_system_include = True
                # Include <...>
                i = 1
                while i < len(tokens):
                    if tokens[i].value == '>':
                        break
                    i += 1
                else:
                    self.on_error(tokens[0].source,tokens[0].lineno,"Malformed #include <...>")
                    return
                filename = "".join([x.value for x in tokens[1:i]])
                path = self.path
            elif tokens[0].type == self.t_STRING:
                filename = tokens[0].value[1:-1]
                path = self.temp_path + self.path
            else:
                self.on_error(tokens[0].source,tokens[0].lineno,"Malformed #include statement")
                return
        while True:
            #print path
            for p in path:
                iname = os.path.join(p,filename)
                fulliname = os.path.abspath(iname)
                if fulliname in self.include_once:
                    if self.debugout is not None:
                        print("x:x:x x:x #include \"%s\" skipped as already seen" % (fulliname), file = self.debugout)
                    return
                try:
                    ih = open(fulliname,"r")
                    data = ih.read()
                    ih.close()
                    dname = os.path.dirname(fulliname)
                    if dname:
                        self.temp_path.insert(0,dname)
                    for tok in self.parsegen(data,filename,fulliname):
                        yield tok
                    if dname:
                        del self.temp_path[0]
                    return
                except IOError:
                    pass
            else:
                p = self.on_include_not_found(is_system_include,self.temp_path[0] if self.temp_path else '',filename)
                if p is None:
                    return
                path.append(p)

    # ----------------------------------------------------------------------
    # define()
    #
    # Define a new macro
    # ----------------------------------------------------------------------

    def define(self,tokens):
        """Define a new macro"""
        if isinstance(tokens,STRING_TYPES):
            tokens = self.tokenize(tokens)
        else:
            tokens = [copy.copy(tok) for tok in tokens]

        linetok = tokens
        try:
            name = linetok[0]
            if len(linetok) > 1:
                mtype = linetok[1]
            else:
                mtype = None
            if not mtype:
                m = Macro(name.value,[])
                self.macros[name.value] = m
            elif mtype.type in self.t_WS:
                # A normal macro
                m = Macro(name.value,self.tokenstrip(linetok[2:]))
                self.macros[name.value] = m
            elif mtype.value == '(':
                # A macro with arguments
                tokcount, args, positions = self.collect_args(linetok[1:])
                variadic = False
                for a in args:
                    if variadic:
                        self.on_error(name.source,name.lineno,"No more arguments may follow a variadic argument")
                        break
                    astr = "".join([str(_i.value) for _i in a])
                    if astr == "...":
                        variadic = True
                        a[0].type = self.t_ID
                        a[0].value = '__VA_ARGS__'
                        variadic = True
                        del a[1:]
                        continue
                    elif astr[-3:] == "..." and a[0].type == self.t_ID:
                        variadic = True
                        del a[1:]
                        # If, for some reason, "." is part of the identifier, strip off the name for the purposes
                        # of macro expansion
                        if a[0].value[-3:] == '...':
                            a[0].value = a[0].value[:-3]
                        continue
                    # Empty arguments are permitted
                    if len(a) == 0 and len(args) == 1:
                        continue
                    if len(a) > 1 or a[0].type != self.t_ID:
                        self.on_error(a.source,a.lineno,"Invalid macro argument")
                        break
                else:
                    mvalue = self.tokenstrip(linetok[1+tokcount:])
                    i = 0
                    while i < len(mvalue):
                        if i+1 < len(mvalue):
                            if mvalue[i].type in self.t_WS and mvalue[i+1].value == '##':
                                del mvalue[i]
                                continue
                            elif mvalue[i].value == '##' and mvalue[i+1].type in self.t_WS:
                                del mvalue[i+1]
                        i += 1
                    m = Macro(name.value,mvalue,[x[0].value for x in args] if args != [[]] else [],variadic)
                    self.macro_prescan(m)
                    self.macros[name.value] = m
            else:
                self.on_error(name.source,name.lineno,"Bad macro definition")
        #except LookupError:
        #    print("Bad macro definition")
        except:
            raise

    # ----------------------------------------------------------------------
    # undef()
    #
    # Undefine a macro
    # ----------------------------------------------------------------------

    def undef(self,tokens):
        """Undefine a macro"""
        if isinstance(tokens,STRING_TYPES):
            tokens = self.tokenize(tokens)
        id = tokens[0].value
        try:
            del self.macros[id]
        except LookupError:
            pass

    # ----------------------------------------------------------------------
    # parse()
    #
    # Parse input text.
    # ----------------------------------------------------------------------
    def parse(self,input,source=None,ignore={}):
        """Parse input text."""
        if isinstance(input, FILE_TYPES):
            if source is None:
                source = input.name
            input = input.read()
        self.ignore = ignore
        self.parser = self.parsegen(input,source,os.path.abspath(source) if source else None)
        if source is not None:
            dname = os.path.dirname(source)
            self.temp_path.insert(0,dname)
        
    # ----------------------------------------------------------------------
    # token()
    #
    # Method to return individual tokens
    # ----------------------------------------------------------------------
    def token(self):
        """Method to return individual tokens"""
        try:
            while True:
                tok = next(self.parser)
                if tok.type not in self.ignore:
                    return tok
        except StopIteration:
            self.parser = None
            return None
            
    def write(self, oh=sys.stdout):
        """Calls token() repeatedly, expanding tokens to their text and writing to the file like stream oh"""
        lastlineno = 0
        lastsource = None
        done = False
        blankacc = []
        blanklines = 0
        while not done:
            emitlinedirective = False
            toks = []
            all_ws = True
            # Accumulate a line
            while not done:
                tok = self.token()
                if not tok:
                    done = True
                    break
                toks.append(tok)
                if tok.value[0] == '\n':
                    break
                if tok.type not in self.t_WS:
                    all_ws = False
            if not toks:
                break
            if all_ws:
                # Remove preceding whitespace so it becomes just a LF
                if len(toks) > 1:
                    tok = toks[-1]
                    toks = [ tok ]
                blankacc.append(toks)
                blanklines += toks[0].value.count('\n')
                continue
            # The line in toks is not all whitespace
            emitlinedirective = (blanklines > 6) and self.line_directive is not None
            if hasattr(toks[0], 'source'):
                if lastsource is None:
                    lastsource = toks[0].source
                elif lastsource != toks[0].source:
                    emitlinedirective = True
                    lastsource = toks[0].source
            # Replace consecutive whitespace in output with a single space except at any indent
            first_ws = None
            for n in xrange(len(toks)-1, -1, -1):
                tok = toks[n]
                if first_ws is None:
                    if tok.type in self.t_SPACE or len(tok.value) == 0:
                        first_ws = n
                else:
                    if tok.type not in self.t_SPACE and len(tok.value) > 0:
                        m = n + 1
                        while m != first_ws:
                            del toks[m]
                            first_ws -= 1
                        first_ws = None
                        # Collapse a token of many whitespace into single
                        if toks[m].value[0] == ' ':
                            toks[m].value = ' '
            if not emitlinedirective:
                newlinesneeded = toks[0].lineno - lastlineno - 1
                if newlinesneeded > 6 and self.line_directive is not None:
                    emitlinedirective = True
                else:
                    while newlinesneeded > 0:
                        oh.write('\n')
                        newlinesneeded -= 1
            lastlineno = toks[0].lineno
            if emitlinedirective and self.line_directive is not None:
                oh.write(self.line_directive + ' ' + str(lastlineno) + ('' if lastsource is None else (' "' + lastsource + '"' )) + '\n')
            #elif blanklines > 0:
            #    for line in blankacc:
            #        for tok in line:
            #            oh.write(tok.value)
            blankacc = []
            blanklines = 0
            #print toks[0].lineno, 
            for tok in toks:
                #print tok.value,
                oh.write(tok.value)
</code></pre>
  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#pcpp.Preprocessor">Preprocessor</a></li>
          <li>__pdoc_file_module__.PreprocessorHooks</li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Methods</h3>
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, lexer=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.__init__', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.__init__" class="source">
    <pre><code>def __init__(self,lexer=None):
    super(Preprocessor, self).__init__()
    if lexer is None:
        import ply.lex as lex
        lexer = lex.lex()
    self.lexer = lexer
    self.macros = { }
    self.path = []
    self.temp_path = []
    self.include_once = {}
    self.return_code = 0
    self.debugout = None
    self.auto_pragma_once_enabled = True
    self.line_directive = '#line'
    # Probe the lexer for selected tokens
    self.__lexprobe()
    tm = time.localtime()
    self.define("__DATE__ \"%s\"" % time.strftime("%b %d %Y",tm))
    self.define("__TIME__ \"%s\"" % time.strftime("%H:%M:%S",tm))
    self.define("__PCPP__ 1")
    self.countermacro = 0
    self.parser = None
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.add_path">
    <p>def <span class="ident">add_path</span>(</p><p>self, path)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds a search path to the preprocessor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.add_path', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.add_path" class="source">
    <pre><code>def add_path(self,path):
    """Adds a search path to the preprocessor. """
    self.path.append(path)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.collect_args">
    <p>def <span class="ident">collect_args</span>(</p><p>self, tokenlist, ignore_errors=False)</p>
    </div>
    

    
  
    <div class="desc"><p>Collects comma separated arguments from a list of tokens.   The arguments
must be enclosed in parenthesis.  Returns a tuple (tokencount,args,positions)
where tokencount is the number of tokens consumed, args is a list of arguments,
and positions is a list of integers containing the starting index of each
argument.  Each argument is represented by a list of tokens.</p>
<p>When collecting arguments, leading and trailing whitespace is removed
from each argument.  </p>
<p>This function properly handles nested parenthesis and commas---these do not
define new arguments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.collect_args', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.collect_args" class="source">
    <pre><code>def collect_args(self,tokenlist,ignore_errors=False):
    """Collects comma separated arguments from a list of tokens.   The arguments
    must be enclosed in parenthesis.  Returns a tuple (tokencount,args,positions)
    where tokencount is the number of tokens consumed, args is a list of arguments,
    and positions is a list of integers containing the starting index of each
    argument.  Each argument is represented by a list of tokens.
    
    When collecting arguments, leading and trailing whitespace is removed
    from each argument.  
    
    This function properly handles nested parenthesis and commas---these do not
    define new arguments."""
    args = []
    positions = []
    current_arg = []
    nesting = 1
    tokenlen = len(tokenlist)

    # Search for the opening '('.
    i = 0
    while (i < tokenlen) and (tokenlist[i].type in self.t_WS):
        i += 1
    if (i < tokenlen) and (tokenlist[i].value == '('):
        positions.append(i+1)
    else:
        if not ignore_errors:
            self.on_error(tokenlist[0].source,tokenlist[0].lineno,"Missing '(' in macro arguments")
        return 0, [], []
    i += 1
    while i < tokenlen:
        t = tokenlist[i]
        if t.value == '(':
            current_arg.append(t)
            nesting += 1
        elif t.value == ')':
            nesting -= 1
            if nesting == 0:
                args.append(self.tokenstrip(current_arg))
                positions.append(i)
                return i+1,args,positions
            current_arg.append(t)
        elif t.value == ',' and nesting == 1:
            args.append(self.tokenstrip(current_arg))
            positions.append(i+1)
            current_arg = []
        else:
            current_arg.append(t)
        i += 1

    # Missing end argument
    if not ignore_errors:
        self.on_error(tokenlist[-1].source,tokenlist[-1].lineno,"Missing ')' in macro arguments")
    return 0, [],[]
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.define">
    <p>def <span class="ident">define</span>(</p><p>self, tokens)</p>
    </div>
    

    
  
    <div class="desc"><p>Define a new macro</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.define', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.define" class="source">
    <pre><code>def define(self,tokens):
    """Define a new macro"""
    if isinstance(tokens,STRING_TYPES):
        tokens = self.tokenize(tokens)
    else:
        tokens = [copy.copy(tok) for tok in tokens]
    linetok = tokens
    try:
        name = linetok[0]
        if len(linetok) > 1:
            mtype = linetok[1]
        else:
            mtype = None
        if not mtype:
            m = Macro(name.value,[])
            self.macros[name.value] = m
        elif mtype.type in self.t_WS:
            # A normal macro
            m = Macro(name.value,self.tokenstrip(linetok[2:]))
            self.macros[name.value] = m
        elif mtype.value == '(':
            # A macro with arguments
            tokcount, args, positions = self.collect_args(linetok[1:])
            variadic = False
            for a in args:
                if variadic:
                    self.on_error(name.source,name.lineno,"No more arguments may follow a variadic argument")
                    break
                astr = "".join([str(_i.value) for _i in a])
                if astr == "...":
                    variadic = True
                    a[0].type = self.t_ID
                    a[0].value = '__VA_ARGS__'
                    variadic = True
                    del a[1:]
                    continue
                elif astr[-3:] == "..." and a[0].type == self.t_ID:
                    variadic = True
                    del a[1:]
                    # If, for some reason, "." is part of the identifier, strip off the name for the purposes
                    # of macro expansion
                    if a[0].value[-3:] == '...':
                        a[0].value = a[0].value[:-3]
                    continue
                # Empty arguments are permitted
                if len(a) == 0 and len(args) == 1:
                    continue
                if len(a) > 1 or a[0].type != self.t_ID:
                    self.on_error(a.source,a.lineno,"Invalid macro argument")
                    break
            else:
                mvalue = self.tokenstrip(linetok[1+tokcount:])
                i = 0
                while i < len(mvalue):
                    if i+1 < len(mvalue):
                        if mvalue[i].type in self.t_WS and mvalue[i+1].value == '##':
                            del mvalue[i]
                            continue
                        elif mvalue[i].value == '##' and mvalue[i+1].type in self.t_WS:
                            del mvalue[i+1]
                    i += 1
                m = Macro(name.value,mvalue,[x[0].value for x in args] if args != [[]] else [],variadic)
                self.macro_prescan(m)
                self.macros[name.value] = m
        else:
            self.on_error(name.source,name.lineno,"Bad macro definition")
    #except LookupError:
    #    print("Bad macro definition")
    except:
        raise
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.evalexpr">
    <p>def <span class="ident">evalexpr</span>(</p><p>self, tokens)</p>
    </div>
    

    
  
    <div class="desc"><p>Evaluate an expression token sequence for the purposes of evaluating
integral expressions.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.evalexpr', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.evalexpr" class="source">
    <pre><code>def evalexpr(self,tokens):
    """Evaluate an expression token sequence for the purposes of evaluating
    integral expressions."""
    if not tokens:
        self.on_error('unknown', 0, "Empty expression")
        return (0, None)
    # tokens = tokenize(line)
    # Search for defined macros
    evalfuncts = {'defined' : lambda x: True}
    evalvars = {}
    i = 0
    while i < len(tokens):
        if tokens[i].type == self.t_ID and tokens[i].value == 'defined':
            j = i + 1
            needparen = False
            result = "0L"
            while j < len(tokens):
                if tokens[j].type in self.t_WS:
                    j += 1
                    continue
                elif tokens[j].type == self.t_ID:
                    if tokens[j].value in self.macros:
                        result = "1L"
                    else:
                        repl = self.on_unknown_macro_in_defined_expr(tokens[j])
                        if repl is None:
                            # Add this identifier to a dictionary of variables
                            evalvars[tokens[j].value] = 0
                            result = 'defined('+tokens[j].value+')'
                        else:
                            result = "1L" if repl else "0L"
                    if not needparen: break
                elif tokens[j].value == '(':
                    needparen = True
                elif tokens[j].value == ')':
                    break
                else:
                    self.on_error(tokens[i].source,tokens[i].lineno,"Malformed defined()")
                j += 1
            if result.startswith('defined'):
                tokens[i].type = self.t_ID
                tokens[i].value = result
            else:
                tokens[i].type = self.t_INTEGER
                tokens[i].value = self.t_INTEGER_TYPE(result)
            del tokens[i+1:j+1]
        i += 1
    tokens = self.expand_macros(tokens)
    if not tokens:
        return (0, None)
    for i,t in enumerate(tokens):
        if t.type == self.t_ID:
            repl = self.on_unknown_macro_in_expr(copy.copy(t))
            if repl is None:
                # Add this identifier to a dictionary of variables
                evalvars[t.value] = 0
            else:
                tokens[i] = t = repl
        if t.type == self.t_INTEGER:
            tokens[i] = copy.copy(t)
            # Strip off any trailing suffixes
            tokens[i].value = str(tokens[i].value)
            while tokens[i].value[-1] not in "0123456789abcdefABCDEF":
                tokens[i].value = tokens[i].value[:-1]
            if sys.version_info.major >= 3:
                if len(tokens[i].value) > 1 and tokens[i].value[0] == '0' and tokens[i].value[1] >= '0' and tokens[i].value[1] <= '7':
                    tokens[i].value = '0o' + tokens[i].value[1:]
        elif t.type == self.t_COLON:
            # Find the expression before the colon
            cs = ce = i - 1
            while cs > 0 and tokens[cs].type in self.t_WS:
                cs -= 1
            if cs > 0 and tokens[cs].value == ')':
                cs -= 1
                brackets = 1
                while cs > 0:
                    if tokens[cs].value == ')':
                        brackets += 1
                    elif tokens[cs].value == '(':
                        brackets -= 1
                        if brackets == 0:
                            break
                    cs -= 1
            while cs > 0 and tokens[cs].type != self.t_TERNARY:
                cs -= 1
            ternary = cs
            cs += 1
            # Find the expression before the ternary
            es = ee = ternary - 1
            while es > 0 and tokens[es].type in self.t_WS:
                es -= 1
            if es > 0 and tokens[es].value == ')':
                es -= 1
                brackets = 1
                while es > 0:
                    if tokens[es].value == ')':
                        brackets += 1
                    elif tokens[es].value == '(':
                        brackets -= 1
                        if brackets == 0:
                            break
                    es -= 1
            else:
                while es > 0 and tokens[es].type not in self.t_WS:
                    es -= 1
                if tokens[es].value == '(':
                    es += 1
            # Swap the pre-ternary and post-ternary expressions
            tokens[ternary].value = ' if '
            tokens[i].value = ' else '
            # Note this is identical length
            tokens = tokens[:es] + tokens[cs:ce+1] + tokens[ternary:ternary+1] + tokens[es:ee+1] + tokens[i:]
    
    expr = origexpr = "".join([str(x.value) for x in tokens if x.type not in self.t_COMMENT])
    expr = expr.replace("&&"," and ")
    expr = expr.replace("||"," or ")
    expr = expr.replace("!="," <> ")
    expr = expr.replace("!"," not ")
    expr = expr.replace(" <> ", " != ")
    try:
        result = int(eval(expr, evalfuncts, evalvars))
    except Exception:
        self.on_error(tokens[0].source,tokens[0].lineno,"Couldn't evaluate expression due to " + traceback.format_exc()
        + "\nConverted expression was " + expr + " with evalvars = " + repr(evalvars))
        result = 0
    return (result, tokens) if evalvars else (result, None)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.expand_macros">
    <p>def <span class="ident">expand_macros</span>(</p><p>self, tokens, expanding_from=[])</p>
    </div>
    

    
  
    <div class="desc"><p>Given a list of tokens, this function performs macro expansion.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.expand_macros', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.expand_macros" class="source">
    <pre><code>def expand_macros(self,tokens,expanding_from=[]):
    """Given a list of tokens, this function performs macro expansion."""
    # Each token needs to track from which macros it has been expanded from to prevent recursion
    for tok in tokens:
        if not hasattr(tok, 'expanded_from'):
            tok.expanded_from = []
    i = 0
    #print "*** EXPAND MACROS in", "".join([t.value for t in tokens]), "expanding_from=", expanding_from
    #print tokens
    #print [(t.value, t.expanded_from) for t in tokens]
    while i < len(tokens):
        t = tokens[i]
        if t.type == self.t_ID:
            if t.value in self.macros and t.value not in t.expanded_from and t.value not in expanding_from:
                # Yes, we found a macro match
                m = self.macros[t.value]
                if m.arglist is None:
                    # A simple macro
                    rep = [copy.copy(_x) for _x in m.value]
                    ex = self.expand_macros(rep, expanding_from + [t.value])
                    #print "\nExpanding macro", m, "\ninto", ex, "\nreplacing", tokens[i:i+1]
                    for e in ex:
                        e.source = t.source
                        e.lineno = t.lineno
                        if not hasattr(e, 'expanded_from'):
                            e.expanded_from = []
                        e.expanded_from.append(t.value)
                    tokens[i:i+1] = ex
                else:
                    # A macro with arguments
                    j = i + 1
                    while j < len(tokens) and (tokens[j].type in self.t_WS or tokens[j].type in self.t_COMMENT):
                        j += 1
                    # A function like macro without an invocation list is to be ignored
                    if j == len(tokens) or tokens[j].value != '(':
                        i = j
                    else:
                        tokcount,args,positions = self.collect_args(tokens[j:], True)
                        if tokcount == 0:
                            # Unclosed parameter list, just bail out
                            break
                        if (not m.variadic
                            # A no arg or single arg consuming macro is permitted to be expanded with nothing
                            and (args != [[]] or len(m.arglist) > 1)
                            and len(args) !=  len(m.arglist)):
                            self.on_error(t.source,t.lineno,"Macro %s requires %d arguments but was passed %d" % (t.value,len(m.arglist),len(args)))
                            i = j + tokcount
                        elif m.variadic and len(args) < len(m.arglist)-1:
                            if len(m.arglist) > 2:
                                self.on_error(t.source,t.lineno,"Macro %s must have at least %d arguments" % (t.value, len(m.arglist)-1))
                            else:
                                self.on_error(t.source,t.lineno,"Macro %s must have at least %d argument" % (t.value, len(m.arglist)-1))
                            i = j + tokcount
                        else:
                            if m.variadic:
                                if len(args) == len(m.arglist)-1:
                                    args.append([])
                                else:
                                    args[len(m.arglist)-1] = tokens[j+positions[len(m.arglist)-1]:j+tokcount-1]
                                    del args[len(m.arglist):]
                            else:
                                # If we called a single arg macro with empty, fake extend args
                                while len(args) < len(m.arglist):
                                    args.append([])
                                    
                            # Get macro replacement text
                            rep = self.macro_expand_args(m,args)
                            ex = self.expand_macros(rep, expanding_from + [t.value])
                            for e in ex:
                                e.source = t.source
                                e.lineno = t.lineno
                                if not hasattr(e, 'expanded_from'):
                                    e.expanded_from = []
                                e.expanded_from.append(t.value)
                            #print "\nExpanding macro", m, "\ninto", ex, "\nreplacing", tokens[i:j+tokcount]
                            tokens[i:j+tokcount] = ex
                continue
            elif t.value == '__LINE__':
                t.type = self.t_INTEGER
                t.value = self.t_INTEGER_TYPE(t.lineno)
            elif t.value == '__COUNTER__':
                t.type = self.t_INTEGER
                t.value = self.t_INTEGER_TYPE(self.countermacro)
                self.countermacro += 1
            
        i += 1
    return tokens
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.group_lines">
    <p>def <span class="ident">group_lines</span>(</p><p>self, input, source)</p>
    </div>
    

    
  
    <div class="desc"><p>Given an input string, this function splits it into lines.  Trailing whitespace
is removed.   Any line ending with \ is grouped with the next line.  This
function forms the lowest level of the preprocessor---grouping into text into
a line-by-line format.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.group_lines', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.group_lines" class="source">
    <pre><code>def group_lines(self,input,source):
    """Given an input string, this function splits it into lines.  Trailing whitespace
    is removed.   Any line ending with \ is grouped with the next line.  This
    function forms the lowest level of the preprocessor---grouping into text into
    a line-by-line format.
    """
    lex = self.lexer.clone()
    lines = [x.rstrip() for x in input.splitlines()]
    for i in xrange(len(lines)):
        j = i+1
        while lines[i].endswith('\\') and (j < len(lines)):
            lines[i] = lines[i][:-1]+lines[j]
            lines[j] = ""
            j += 1
    input = "\n".join(lines)
    lex.input(input)
    lex.lineno = 1
    current_line = []
    while True:
        tok = lex.token()
        if not tok:
            break
        tok.source = source
        current_line.append(tok)
        if tok.type in self.t_WS and '\n' in tok.value:
            yield current_line
            current_line = []
    if current_line:
        nltok = copy.copy(current_line[-1])
        nltok.type = self.t_NEWLINE
        nltok.value = '\n'
        current_line.append(nltok)
        yield current_line
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.include">
    <p>def <span class="ident">include</span>(</p><p>self, tokens)</p>
    </div>
    

    
  
    <div class="desc"><p>Implementation of file-inclusion</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.include', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.include" class="source">
    <pre><code>def include(self,tokens):
    """Implementation of file-inclusion"""
    # Try to extract the filename and then process an include file
    if not tokens:
        return
    if tokens:
        if tokens[0].value != '<' and tokens[0].type != self.t_STRING:
            tokens = self.tokenstrip(self.expand_macros(tokens))
        is_system_include = False
        if tokens[0].value == '<':
            is_system_include = True
            # Include <...>
            i = 1
            while i < len(tokens):
                if tokens[i].value == '>':
                    break
                i += 1
            else:
                self.on_error(tokens[0].source,tokens[0].lineno,"Malformed #include <...>")
                return
            filename = "".join([x.value for x in tokens[1:i]])
            path = self.path
        elif tokens[0].type == self.t_STRING:
            filename = tokens[0].value[1:-1]
            path = self.temp_path + self.path
        else:
            self.on_error(tokens[0].source,tokens[0].lineno,"Malformed #include statement")
            return
    while True:
        #print path
        for p in path:
            iname = os.path.join(p,filename)
            fulliname = os.path.abspath(iname)
            if fulliname in self.include_once:
                if self.debugout is not None:
                    print("x:x:x x:x #include \"%s\" skipped as already seen" % (fulliname), file = self.debugout)
                return
            try:
                ih = open(fulliname,"r")
                data = ih.read()
                ih.close()
                dname = os.path.dirname(fulliname)
                if dname:
                    self.temp_path.insert(0,dname)
                for tok in self.parsegen(data,filename,fulliname):
                    yield tok
                if dname:
                    del self.temp_path[0]
                return
            except IOError:
                pass
        else:
            p = self.on_include_not_found(is_system_include,self.temp_path[0] if self.temp_path else '',filename)
            if p is None:
                return
            path.append(p)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.macro_expand_args">
    <p>def <span class="ident">macro_expand_args</span>(</p><p>self, macro, args)</p>
    </div>
    

    
  
    <div class="desc"><p>Given a Macro and list of arguments (each a token list), this method
returns an expanded version of a macro.  The return value is a token sequence
representing the replacement macro tokens</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.macro_expand_args', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.macro_expand_args" class="source">
    <pre><code>def macro_expand_args(self,macro,args):
    """Given a Macro and list of arguments (each a token list), this method
    returns an expanded version of a macro.  The return value is a token sequence
    representing the replacement macro tokens"""
    # Make a copy of the macro token sequence
    rep = [copy.copy(_x) for _x in macro.value]
    # Make string expansion patches.  These do not alter the length of the replacement sequence
    str_expansion = {}
    for argnum, i in macro.str_patch:
        if argnum not in str_expansion:
            # Strip all non-space whitespace before stringization
            tokens = copy.copy(args[argnum])
            for j in xrange(len(tokens)):
                if tokens[j].type in self.t_WS:
                    tokens[j].value = ' '
            # Collapse all multiple whitespace too
            j = 0
            while j < len(tokens) - 1:
                if tokens[j].type in self.t_WS and tokens[j+1].type in self.t_WS:
                    del tokens[j+1]
                else:
                    j += 1
            str = "".join([x.value for x in tokens])
            str = str.replace("\\","\\\\").replace('"', '\\"')
            str_expansion[argnum] = '"' + str + '"'
        rep[i] = copy.copy(rep[i])
        rep[i].value = str_expansion[argnum]
    # Make the variadic macro comma patch.  If the variadic macro argument is empty, we get rid
    comma_patch = False
    if macro.variadic and not args[-1]:
        for i in macro.var_comma_patch:
            rep[i] = None
            comma_patch = True
    # Make all other patches.   The order of these matters.  It is assumed that the patch list
    # has been sorted in reverse order of patch location since replacements will cause the
    # size of the replacement sequence to expand from the patch point.
    
    expanded = { }
    #print "***", macro
    #print macro.patch
    for ptype, argnum, i in macro.patch:
        # Concatenation.   Argument is left unexpanded
        if ptype == 't':
            rep[i:i+1] = args[argnum]
        # Normal expansion.  Argument is macro expanded first
        elif ptype == 'e':
            if argnum not in expanded:
                expanded[argnum] = self.expand_macros(args[argnum])
            rep[i:i+1] = expanded[argnum]
    # Get rid of removed comma if necessary
    if comma_patch:
        rep = [_i for _i in rep if _i]
        
    # Do a token concatenation pass, stitching any tokens separated by ## into a single token
    while len(rep) and rep[0].type == self.t_DPOUND:
        del rep[0]
    while len(rep) and rep[-1].type == self.t_DPOUND:
        del rep[-1]
    i = 1
    while i < len(rep) - 1:
        if rep[i].type == self.t_DPOUND:
            j = i + 1
            while rep[j].type == self.t_DPOUND:
                j += 1
            rep[i-1].type = self.t_ID
            rep[i-1].value += rep[j].value
            while j >= i:
                del rep[i]
                j -= 1
        else:
            i += 1
    #print rep
    return rep
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.macro_prescan">
    <p>def <span class="ident">macro_prescan</span>(</p><p>self, macro)</p>
    </div>
    

    
  
    <div class="desc"><p>Examine the macro value (token sequence) and identify patch points
This is used to speed up macro expansion later on---we'll know
right away where to apply patches to the value to form the expansion</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.macro_prescan', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.macro_prescan" class="source">
    <pre><code>def macro_prescan(self,macro):
    """Examine the macro value (token sequence) and identify patch points
    This is used to speed up macro expansion later on---we'll know
    right away where to apply patches to the value to form the expansion"""
    macro.patch     = []             # Standard macro arguments 
    macro.str_patch = []             # String conversion expansion
    macro.var_comma_patch = []       # Variadic macro comma patch
    i = 0
    #print "BEFORE", macro.value
    while i < len(macro.value):
        if macro.value[i].type == self.t_ID and macro.value[i].value in macro.arglist:
            argnum = macro.arglist.index(macro.value[i].value)
            # Conversion of argument to a string
            j = i - 1
            while j >= 0 and macro.value[j].type in self.t_WS:
                j -= 1
            if j >= 0 and macro.value[j].value == '#':
                macro.value[i] = copy.copy(macro.value[i])
                macro.value[i].type = self.t_STRING
                while i > j:
                    del macro.value[j]
                    i -= 1
                macro.str_patch.append((argnum,i))
                continue
            # Concatenation
            elif (i > 0 and macro.value[i-1].value == '##'):
                macro.patch.append(('t',argnum,i))
                i += 1
                continue
            elif ((i+1) < len(macro.value) and macro.value[i+1].value == '##'):
                macro.patch.append(('t',argnum,i))
                i += 1
                continue
            # Standard expansion
            else:
                macro.patch.append(('e',argnum,i))
        elif macro.value[i].value == '##':
            if macro.variadic and (i > 0) and (macro.value[i-1].value == ',') and \
                    ((i+1) < len(macro.value)) and (macro.value[i+1].type == self.t_ID) and \
                    (macro.value[i+1].value == macro.vararg):
                macro.var_comma_patch.append(i-1)
        i += 1
    macro.patch.sort(key=lambda x: x[2],reverse=True)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_comment">
    <p>def <span class="ident">on_comment</span>(</p><p>self, tok)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when the preprocessor encounters a comment token. You can modify the token
in place, or do nothing to let the comment pass through.</p>
<p>The default modifies the token to become whitespace, becoming a single space if the
comment is a block comment, else a single new line if the comment is a line comment.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_comment', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_comment" class="source">
    <pre><code>def on_comment(self,tok):
    """Called when the preprocessor encounters a comment token. You can modify the token
    in place, or do nothing to let the comment pass through.
    
    The default modifies the token to become whitespace, becoming a single space if the
    comment is a block comment, else a single new line if the comment is a line comment.
    """
    if tok.type == self.t_COMMENT1:
        tok.value = ' '
    elif tok.type == self.t_COMMENT2:
        tok.value = '\n'
    tok.type = 'CPP_WS'
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_directive_handle">
    <p>def <span class="ident">on_directive_handle</span>(</p><p>self, directive, toks, ifpassthru)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when there is one of</p>
<p>define, include, undef, ifdef, ifndef, if, elif, else, endif</p>
<p>Return True to execute and remove from the output, return False to
remove from the output, raise OutputDirective to pass through without
execution, or return None to execute AND pass through to the output
(this only works for #define, #undef).</p>
<p>The default returns True (execute and remove from the output).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_directive_handle', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_directive_handle" class="source">
    <pre><code>def on_directive_handle(self,directive,toks,ifpassthru):
    """Called when there is one of
    
    define, include, undef, ifdef, ifndef, if, elif, else, endif
    
    Return True to execute and remove from the output, return False to
    remove from the output, raise OutputDirective to pass through without
    execution, or return None to execute AND pass through to the output
    (this only works for #define, #undef).
    
    The default returns True (execute and remove from the output).
    """
    self.lastdirective = directive
    return True
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_directive_unknown">
    <p>def <span class="ident">on_directive_unknown</span>(</p><p>self, directive, toks, ifpassthru)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when the preprocessor encounters a #directive it doesn't understand.
This is actually quite an extensive list as it currently only understands:</p>
<p>define, include, undef, ifdef, ifndef, if, elif, else, endif</p>
<p>Return True or False to remove from the output, or else raise OutputDirective
or return None to pass through into the output.</p>
<p>The default handles #error and #warning by printing to stderr and returning True
(remove from output). For everything else it returns None (pass through into output).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_directive_unknown', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_directive_unknown" class="source">
    <pre><code>def on_directive_unknown(self,directive,toks,ifpassthru):
    """Called when the preprocessor encounters a #directive it doesn't understand.
    This is actually quite an extensive list as it currently only understands:
    
    define, include, undef, ifdef, ifndef, if, elif, else, endif
    
    Return True or False to remove from the output, or else raise OutputDirective
    or return None to pass through into the output.
    
    The default handles #error and #warning by printing to stderr and returning True
    (remove from output). For everything else it returns None (pass through into output).
    """
    if directive.value == 'error':
        print("%s:%d error: %s" % (directive.source,directive.lineno,''.join(tok.value for tok in toks)), file = sys.stderr)
        self.return_code += 1
        return True
    elif directive.value == 'warning':
        print("%s:%d warning: %s" % (directive.source,directive.lineno,''.join(tok.value for tok in toks)), file = sys.stderr)
        return True
    return None
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_error">
    <p>def <span class="ident">on_error</span>(</p><p>self, file, line, msg)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when the preprocessor has encountered an error, e.g. malformed input.</p>
<p>The default simply prints to stderr and increments the return code.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_error', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_error" class="source">
    <pre><code>def on_error(self,file,line,msg):
    """Called when the preprocessor has encountered an error, e.g. malformed input.
    
    The default simply prints to stderr and increments the return code.
    """
    print("%s:%d error: %s" % (file,line,msg), file = sys.stderr)
    self.return_code += 1
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_include_not_found">
    <p>def <span class="ident">on_include_not_found</span>(</p><p>self, is_system_include, curdir, includepath)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when a #include wasn't found.</p>
<p>Return None to ignore, raise OutputDirective to pass through, else return
a suitable path. Remember that Preprocessor.add_path() lets you add search paths.</p>
<p>The default calls self.on_error() with a suitable error message about the
include file not found and raises OutputDirective (pass through).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_include_not_found', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_include_not_found" class="source">
    <pre><code>def on_include_not_found(self,is_system_include,curdir,includepath):
    """Called when a #include wasn't found.
    
    Return None to ignore, raise OutputDirective to pass through, else return
    a suitable path. Remember that Preprocessor.add_path() lets you add search paths.
    
    The default calls self.on_error() with a suitable error message about the
    include file not found and raises OutputDirective (pass through).
    """
    self.on_error(self.lastdirective.source,self.lastdirective.lineno, "Include file '%s' not found" % includepath)
    raise OutputDirective()
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_potential_include_guard">
    <p>def <span class="ident">on_potential_include_guard</span>(</p><p>self, macro)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when the preprocessor encounters an #ifndef macro or an #if !defined(macro)
as the first non-whitespace thing in a file. Unlike the other hooks, macro is a string,
not a token.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_potential_include_guard', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_potential_include_guard" class="source">
    <pre><code>def on_potential_include_guard(self,macro):
    """Called when the preprocessor encounters an #ifndef macro or an #if !defined(macro)
    as the first non-whitespace thing in a file. Unlike the other hooks, macro is a string,
    not a token.
    """
    pass
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_unknown_macro_in_defined_expr">
    <p>def <span class="ident">on_unknown_macro_in_defined_expr</span>(</p><p>self, tok)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when an expression passed to an #if contained a defined operator
performed on something unknown.</p>
<p>Return True if to treat it as defined, False if to treat it as undefined,
raise OutputDirective to pass through without execution, or return None to
pass through the mostly expanded #if expression apart from the unknown defined.</p>
<p>The default returns False, as per the C standard.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_unknown_macro_in_defined_expr', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_unknown_macro_in_defined_expr" class="source">
    <pre><code>def on_unknown_macro_in_defined_expr(self,tok):
    """Called when an expression passed to an #if contained a defined operator
    performed on something unknown.
    
    Return True if to treat it as defined, False if to treat it as undefined,
    raise OutputDirective to pass through without execution, or return None to
    pass through the mostly expanded #if expression apart from the unknown defined.
    
    The default returns False, as per the C standard.
    """
    return False
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.on_unknown_macro_in_expr">
    <p>def <span class="ident">on_unknown_macro_in_expr</span>(</p><p>self, tok)</p>
    </div>
    

    
  
    <div class="desc"><p>Called when an expression passed to an #if contained something unknown.</p>
<p>Return what value it should be, raise OutputDirective to pass through
without execution, or return None to pass through the mostly expanded #if
expression apart from the unknown item.</p>
<p>The default returns a token for an integer 0L, as per the C standard.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.on_unknown_macro_in_expr', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.on_unknown_macro_in_expr" class="source">
    <pre><code>def on_unknown_macro_in_expr(self,tok):
    """Called when an expression passed to an #if contained something unknown.
    
    Return what value it should be, raise OutputDirective to pass through
    without execution, or return None to pass through the mostly expanded #if
    expression apart from the unknown item.
    
    The default returns a token for an integer 0L, as per the C standard.
    """
    tok.type = self.t_INTEGER
    tok.value = self.t_INTEGER_TYPE("0L")
    return tok
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.parse">
    <p>def <span class="ident">parse</span>(</p><p>self, input, source=None, ignore={})</p>
    </div>
    

    
  
    <div class="desc"><p>Parse input text.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.parse', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.parse" class="source">
    <pre><code>def parse(self,input,source=None,ignore={}):
    """Parse input text."""
    if isinstance(input, FILE_TYPES):
        if source is None:
            source = input.name
        input = input.read()
    self.ignore = ignore
    self.parser = self.parsegen(input,source,os.path.abspath(source) if source else None)
    if source is not None:
        dname = os.path.dirname(source)
        self.temp_path.insert(0,dname)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.parsegen">
    <p>def <span class="ident">parsegen</span>(</p><p>self, input, source=None, abssource=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Parse an input string</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.parsegen', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.parsegen" class="source">
    <pre><code>def parsegen(self,input,source=None,abssource=None):
    """Parse an input string"""
    # Replace trigraph sequences
    t = trigraph(input)
    lines = self.group_lines(t, source)
    if not source:
        source = ""
        
    self.define("__FILE__ \"%s\"" % source)
    self.source = abssource
    chunk = []
    enable = True
    iftrigger = False
    ifpassthru = False
    class ifstackentry(object):
        def __init__(self,enable,iftrigger,ifpassthru,startlinetoks):
            self.enable = enable
            self.iftrigger = iftrigger
            self.ifpassthru = ifpassthru
            self.rewritten = False
            self.startlinetoks = startlinetoks
    ifstack = []
    # True until any non-whitespace output or anything with effects happens.
    at_front_of_file = True
    # True if auto pragma once still a possibility for this #include
    auto_pragma_once_possible = self.auto_pragma_once_enabled
    # =(MACRO, 0) means #ifndef MACRO or #if !defined(MACRO) seen, =(MACRO,1) means #define MACRO seen
    include_guard = None
    self.on_potential_include_guard(None)
    for x in lines:
        all_whitespace = True
        skip_auto_pragma_once_possible_check = False
        # Handle comments
        for i,tok in enumerate(x):
            if tok.type in self.t_COMMENT:
                self.on_comment(tok)
        # Skip over whitespace
        for i,tok in enumerate(x):
            if tok.type not in self.t_WS and tok.type not in self.t_COMMENT:
                all_whitespace = False
                break
        output_and_expand_line = True
        output_unexpanded_line = False
        if tok.value == '#':
            output_and_expand_line = False
            try:
                # Preprocessor directive      
                i += 1
                while x[i].type in self.t_WS:
                    i += 1                    
                dirtokens = self.tokenstrip(x[i:])
                if dirtokens:
                    name = dirtokens[0].value
                    args = self.tokenstrip(dirtokens[1:])
                else:
                    name = ""
                    args = []
                
                if self.debugout is not None:
                    print("%d:%d:%d %s:%d #%s %s" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno, dirtokens[0].value, "".join([tok.value for tok in args])), file = self.debugout)
                    #print(ifstack)
                handling = self.on_directive_handle(dirtokens[0],args,ifpassthru)
                if handling == False:
                    pass
                elif name == 'define':
                    at_front_of_file = False
                    if enable:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        if include_guard and include_guard[0] == args[0].value:
                            include_guard = (args[0].value, 1)
                            # If ifpassthru is only turned on due to this include guard, turn it off
                            if ifpassthru and not ifstack[-1].ifpassthru:
                                ifpassthru = False
                        self.define(args)
                        if self.debugout is not None:
                            print("%d:%d:%d %s:%d      %s" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno, repr(self.macros[args[0].value])), file = self.debugout)
                        if handling is None:
                            for tok in x:
                                yield tok
                elif name == 'include':
                    if enable:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        oldfile = self.macros['__FILE__']
                        for tok in self.include(args):
                            yield tok
                        self.macros['__FILE__'] = oldfile
                        self.source = abssource
                elif name == 'undef':
                    at_front_of_file = False
                    if enable:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        self.undef(args)
                        if handling is None:
                            for tok in x:
                                yield tok
                elif name == 'ifdef':
                    at_front_of_file = False
                    ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                    if enable:
                        ifpassthru = False
                        if not args[0].value in self.macros:
                            res = self.on_unknown_macro_in_defined_expr(args[0])
                            if res is None:
                                ifpassthru = True
                                ifstack[-1].rewritten = True
                                raise OutputDirective()
                            elif res is True:
                                iftrigger = True
                            else:
                                enable = False
                                iftrigger = False
                        else:
                            iftrigger = True
                elif name == 'ifndef':
                    if not ifstack and at_front_of_file:
                        self.on_potential_include_guard(args[0].value)
                        include_guard = (args[0].value, 0)
                    at_front_of_file = False
                    ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                    if enable:
                        ifpassthru = False
                        if args[0].value in self.macros:
                            enable = False
                            iftrigger = False
                        else:
                            res = self.on_unknown_macro_in_defined_expr(args[0])
                            if res is None:
                                ifpassthru = True
                                ifstack[-1].rewritten = True
                                raise OutputDirective()
                            elif res is True:
                                enable = False
                                iftrigger = False
                            else:
                                iftrigger = True
                elif name == 'if':
                    if not ifstack and at_front_of_file:
                        if args[0].value == '!' and args[1].value == 'defined':
                            n = 2
                            if args[n].value == '(': n += 1
                            self.on_potential_include_guard(args[n].value)
                            include_guard = (args[n].value, 0)
                    at_front_of_file = False
                    ifstack.append(ifstackentry(enable,iftrigger,ifpassthru,x))
                    if enable:
                        ifpassthru = False
                        result, rewritten = self.evalexpr(args)
                        if rewritten is not None:
                            x = x[:i+2] + rewritten + [x[-1]]
                            x[i+1] = copy.copy(x[i+1])
                            x[i+1].type = self.t_SPACE
                            x[i+1].value = ' '
                            ifpassthru = True
                            ifstack[-1].rewritten = True
                            raise OutputDirective()
                        if not result:
                            enable = False
                            iftrigger = False
                        else:
                            iftrigger = True
                elif name == 'elif':
                    at_front_of_file = False
                    if ifstack:
                        if ifstack[-1].enable:     # We only pay attention if outer "if" allows this
                            if enable and not ifpassthru:         # If already true, we flip enable False
                                enable = False
                            elif not iftrigger:   # If False, but not triggered yet, we'll check expression
                                result, rewritten = self.evalexpr(args)
                                if rewritten is not None:
                                    enable = True
                                    if not ifpassthru:
                                        # This is a passthru #elif after a False #if, so convert to an #if
                                        x[i].value = 'if'
                                    x = x[:i+2] + rewritten + [x[-1]]
                                    x[i+1] = copy.copy(x[i+1])
                                    x[i+1].type = self.t_SPACE
                                    x[i+1].value = ' '
                                    ifpassthru = True
                                    ifstack[-1].rewritten = True
                                    raise OutputDirective()
                                if ifpassthru:
                                    # If this elif can only ever be true, simulate that
                                    if result:
                                        newtok = copy.copy(x[i+3])
                                        newtok.type = self.t_INTEGER
                                        newtok.value = self.t_INTEGER_TYPE(result)
                                        x = x[:i+2] + [newtok] + [x[-1]]
                                        raise OutputDirective()
                                    # Otherwise elide
                                    enable = False
                                elif result:
                                    enable  = True
                                    iftrigger = True
                    else:
                        self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #elif")
                        
                elif name == 'else':
                    at_front_of_file = False
                    if ifstack:
                        if ifstack[-1].enable:
                            if ifpassthru:
                                enable = True
                                raise OutputDirective()
                            if enable:
                                enable = False
                            elif not iftrigger:
                                enable = True
                                iftrigger = True
                    else:
                        self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #else")
                elif name == 'endif':
                    at_front_of_file = False
                    if ifstack:
                        oldifstackentry = ifstack.pop()
                        enable = oldifstackentry.enable
                        iftrigger = oldifstackentry.iftrigger
                        ifpassthru = oldifstackentry.ifpassthru
                        if self.debugout is not None:
                            print("%d:%d:%d %s:%d      (%s:%d %s)" % (enable, iftrigger, ifpassthru, dirtokens[0].source, dirtokens[0].lineno,
                                oldifstackentry.startlinetoks[0].source, oldifstackentry.startlinetoks[0].lineno, "".join([n.value for n in oldifstackentry.startlinetoks])), file = self.debugout)
                        skip_auto_pragma_once_possible_check = True
                        if oldifstackentry.rewritten:
                            raise OutputDirective()
                    else:
                        self.on_error(dirtokens[0].source,dirtokens[0].lineno,"Misplaced #endif")
                elif name == 'pragma' and args[0].value == 'once':
                    if enable:
                        self.include_once[self.source] = None
                elif enable:
                    # Unknown preprocessor directive
                    output_unexpanded_line = (self.on_directive_unknown(dirtokens[0], args, ifpassthru) is None)
            except OutputDirective:
                output_unexpanded_line = True
        # If there is ever any non-whitespace output outside an include guard, auto pragma once is not possible
        if not skip_auto_pragma_once_possible_check and auto_pragma_once_possible and not ifstack and not all_whitespace:
            auto_pragma_once_possible = False
            if self.debugout is not None:
                print("%d:%d:%d %s:%d Determined that #include \"%s\" is not entirely wrapped in an include guard macro, disabling auto-applying #pragma once" % (enable, iftrigger, ifpassthru, x[0].source, x[0].lineno, self.source), file = self.debugout)
            
        if output_and_expand_line or output_unexpanded_line:
            if not all_whitespace:
                at_front_of_file = False
            # Normal text
            if enable:
                if output_and_expand_line:
                    chunk.extend(x)
                elif output_unexpanded_line:
                    for tok in self.expand_macros(chunk):
                        yield tok
                    chunk = []
                    for tok in x:
                        yield tok
            else:
                # Need to extend with the same number of blank lines
                i = 0
                while i < len(x):
                    if x[i].type not in self.t_WS:
                        del x[i]
                    else:
                        i += 1
                chunk.extend(x)
    for tok in self.expand_macros(chunk):
        yield tok
    chunk = []
    for i in ifstack:
        self.on_error(i.startlinetoks[0].source, i.startlinetoks[0].lineno, "Unterminated " + "".join([n.value for n in i.startlinetoks]))
    if auto_pragma_once_possible and include_guard and include_guard[1] == 1:
        if self.debugout is not None:
            print("%d:%d:%d %s:%d Determined that #include \"%s\" is entirely wrapped in an include guard macro called %s, auto-applying #pragma once" % (enable, iftrigger, ifpassthru, self.source, 0, self.source, include_guard[0]), file = self.debugout)
        self.include_once[self.source] = include_guard[0]
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.token">
    <p>def <span class="ident">token</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Method to return individual tokens</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.token', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.token" class="source">
    <pre><code>def token(self):
    """Method to return individual tokens"""
    try:
        while True:
            tok = next(self.parser)
            if tok.type not in self.ignore:
                return tok
    except StopIteration:
        self.parser = None
        return None
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.tokenize">
    <p>def <span class="ident">tokenize</span>(</p><p>self, text)</p>
    </div>
    

    
  
    <div class="desc"><p>Utility function. Given a string of text, tokenize into a list of tokens</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.tokenize', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.tokenize" class="source">
    <pre><code>def tokenize(self,text):
    """Utility function. Given a string of text, tokenize into a list of tokens"""
    tokens = []
    self.lexer.input(text)
    while True:
        tok = self.lexer.token()
        if not tok: break
        tokens.append(tok)
    return tokens
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.tokenstrip">
    <p>def <span class="ident">tokenstrip</span>(</p><p>self, tokens)</p>
    </div>
    

    
  
    <div class="desc"><p>Remove leading/trailing whitespace tokens from a token list</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.tokenstrip', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.tokenstrip" class="source">
    <pre><code>def tokenstrip(self,tokens):
    """Remove leading/trailing whitespace tokens from a token list"""
    i = 0
    while i < len(tokens) and tokens[i].type in self.t_WS:
        i += 1
    del tokens[:i]
    i = len(tokens)-1
    while i >= 0 and tokens[i].type in self.t_WS:
        i -= 1
    del tokens[i+1:]
    return tokens
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.undef">
    <p>def <span class="ident">undef</span>(</p><p>self, tokens)</p>
    </div>
    

    
  
    <div class="desc"><p>Undefine a macro</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.undef', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.undef" class="source">
    <pre><code>def undef(self,tokens):
    """Undefine a macro"""
    if isinstance(tokens,STRING_TYPES):
        tokens = self.tokenize(tokens)
    id = tokens[0].value
    try:
        del self.macros[id]
    except LookupError:
        pass
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="pcpp.Preprocessor.write">
    <p>def <span class="ident">write</span>(</p><p>self, oh=&lt;open file &#39;&lt;stdout&gt;&#39;, mode &#39;w&#39; at 0x7f3098c02150&gt;)</p>
    </div>
    

    
  
    <div class="desc"><p>Calls token() repeatedly, expanding tokens to their text and writing to the file like stream oh</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-pcpp.Preprocessor.write', this);">Show source &equiv;</a></p>
  <div id="source-pcpp.Preprocessor.write" class="source">
    <pre><code>def write(self, oh=sys.stdout):
    """Calls token() repeatedly, expanding tokens to their text and writing to the file like stream oh"""
    lastlineno = 0
    lastsource = None
    done = False
    blankacc = []
    blanklines = 0
    while not done:
        emitlinedirective = False
        toks = []
        all_ws = True
        # Accumulate a line
        while not done:
            tok = self.token()
            if not tok:
                done = True
                break
            toks.append(tok)
            if tok.value[0] == '\n':
                break
            if tok.type not in self.t_WS:
                all_ws = False
        if not toks:
            break
        if all_ws:
            # Remove preceding whitespace so it becomes just a LF
            if len(toks) > 1:
                tok = toks[-1]
                toks = [ tok ]
            blankacc.append(toks)
            blanklines += toks[0].value.count('\n')
            continue
        # The line in toks is not all whitespace
        emitlinedirective = (blanklines > 6) and self.line_directive is not None
        if hasattr(toks[0], 'source'):
            if lastsource is None:
                lastsource = toks[0].source
            elif lastsource != toks[0].source:
                emitlinedirective = True
                lastsource = toks[0].source
        # Replace consecutive whitespace in output with a single space except at any indent
        first_ws = None
        for n in xrange(len(toks)-1, -1, -1):
            tok = toks[n]
            if first_ws is None:
                if tok.type in self.t_SPACE or len(tok.value) == 0:
                    first_ws = n
            else:
                if tok.type not in self.t_SPACE and len(tok.value) > 0:
                    m = n + 1
                    while m != first_ws:
                        del toks[m]
                        first_ws -= 1
                    first_ws = None
                    # Collapse a token of many whitespace into single
                    if toks[m].value[0] == ' ':
                        toks[m].value = ' '
        if not emitlinedirective:
            newlinesneeded = toks[0].lineno - lastlineno - 1
            if newlinesneeded > 6 and self.line_directive is not None:
                emitlinedirective = True
            else:
                while newlinesneeded > 0:
                    oh.write('\n')
                    newlinesneeded -= 1
        lastlineno = toks[0].lineno
        if emitlinedirective and self.line_directive is not None:
            oh.write(self.line_directive + ' ' + str(lastlineno) + ('' if lastsource is None else (' "' + lastsource + '"' )) + '\n')
        #elif blanklines > 0:
        #    for line in blankacc:
        #        for tok in line:
        #            oh.write(tok.value)
        blankacc = []
        blanklines = 0
        #print toks[0].lineno, 
        for tok in toks:
            #print tok.value,
            oh.write(tok.value)
</code></pre>
  </div>
</div>

  </div>
  
      </div>
      </div>

  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.2</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
